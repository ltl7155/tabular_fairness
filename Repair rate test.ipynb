{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed39ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_census_income\n",
    "import tensorflow.keras.backend as KTF\n",
    "import argparse\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(constraint[i][0], constraint[i][1]+1))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "def get_repaired_num(newdata_res):\n",
    "    # identify whether the instance is discriminatory w.r.t. the model\n",
    "    # print(x.shape)\n",
    "    # print(X_train[0].shape)\n",
    "    # y_pred = (model(tf.constant([X_train[0]])) > 0.5)\n",
    "    l = len(newdata_res)\n",
    "    for i in range(l-1):\n",
    "        tmp_acc = (newdata_res[i] == newdata_res[i + 1]) * 1\n",
    "        if i == 0:\n",
    "            acc = tmp_acc\n",
    "        else:\n",
    "            acc += tmp_acc\n",
    "    return np.sum(np.where(acc == l-1, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e4f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr a\n",
      "WARNING:tensorflow:From /home/xiaofei/anaconda3/envs/debias/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/xiaofei/anaconda3/envs/debias/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/xiaofei/anaconda3/envs/debias/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Aug 0.4348434156697388\n",
      "attr r\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Aug 0.8528403018169637\n",
      "attr g\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Aug 0.7104122329944037\n",
      "attr a&r\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, constraint = pre_census_income.X_train, \\\n",
    "    pre_census_income.X_val, pre_census_income.y_train, pre_census_income.y_val, pre_census_income.constraint\n",
    "    \n",
    "X_test, y_test = pre_census_income.X_test, pre_census_income.y_test\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "models_map = { 'a': \"models/retrained_adv/a_adult_model_0.h5\",\n",
    "            'r': \"models/retrained_adv/r_adult_model_0.h5\",\n",
    "            'g': \"models/retrained_adv/g_adult_model_0.h5\",\n",
    "            'a&r': \"models/retrained_adv/a&r_adult_model_0.h5\",\n",
    "            'a&g': \"models/retrained_adv/a&g_adult_model_0.h5\",\n",
    "            'r&g': \"models/retrained_adv/r&g_adult_model_0.h5\",\n",
    "    \n",
    "}\n",
    "\n",
    "for attr in pos_map.keys():\n",
    "    print(\"attr\", attr)\n",
    "    target_model_path = models_map[attr]\n",
    "    data_name = f\"discriminatory_data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "    dis_data = np.load(data_name)\n",
    "    num_attribs = len(X_train[0])\n",
    "    protected_attribs = pos_map[attr]\n",
    "    similar_X = similar_set(dis_data, num_attribs, protected_attribs, constraint)\n",
    "\n",
    "    augmented_model = keras.models.load_model(target_model_path)\n",
    "    aug_data = (augmented_model.predict(dis_data) > 0.5).astype(int).flatten()\n",
    "    dis_num = 0\n",
    "    newdata_res = []\n",
    "\n",
    "    l = len(similar_X)\n",
    "    for i in range(l):\n",
    "        newdata_re = augmented_model.predict(similar_X[i])\n",
    "        newdata_re = (newdata_re > 0.5).astype(int).flatten()\n",
    "        newdata_res.append(newdata_re)\n",
    "    repaired_num = get_repaired_num(newdata_res)\n",
    "\n",
    "    print('Aug', repaired_num/len(dis_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, constraint = pre_census_income.X_train, \\\n",
    "    pre_census_income.X_val, pre_census_income.y_train, pre_census_income.y_val, pre_census_income.constraint\n",
    "    \n",
    "X_test, y_test = pre_census_income.X_test, pre_census_income.y_test\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "models_map = { 'a': \"models/models_my_attribute_wise_retrain/adult_a_EIDIG_INF_retrained_model.h5\",\n",
    "            'r': \"models/models_my_attribute_wise_retrain/adult_r_EIDIG_INF_retrained_model.h5\",\n",
    "            'g': \"models/models_my_attribute_wise_retrain/adult_g_EIDIG_INF_retrained_model.h5\",\n",
    "            'a&r': \"models/models_my_attribute_wise_retrain/adult_a&r_EIDIG_INF_retrained_model.h5\",\n",
    "            'a&g': \"models/models_my_attribute_wise_retrain/adult_a&g_EIDIG_INF_retrained_model.h5\",\n",
    "            'r&g': \"models/models_my_attribute_wise_retrain/adult_r&g_EIDIG_INF_retrained_model.h5\",\n",
    "    \n",
    "}\n",
    "\n",
    "for attr in pos_map.keys():\n",
    "    print(\"attr\", attr)\n",
    "    target_model_path = models_map[attr]\n",
    "    data_name = f\"discriminatory_data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "    dis_data = np.load(data_name)\n",
    "    num_attribs = len(X_train[0])\n",
    "    protected_attribs = pos_map[attr]\n",
    "    similar_X = similar_set(dis_data, num_attribs, protected_attribs, constraint)\n",
    "\n",
    "    augmented_model = keras.models.load_model(target_model_path)\n",
    "    aug_data = (augmented_model.predict(dis_data) > 0.5).astype(int).flatten()\n",
    "    dis_num = 0\n",
    "    newdata_res = []\n",
    "\n",
    "    l = len(similar_X)\n",
    "    for i in range(l):\n",
    "        newdata_re = augmented_model.predict(similar_X[i])\n",
    "        newdata_re = (newdata_re > 0.5).astype(int).flatten()\n",
    "        newdata_res.append(newdata_re)\n",
    "    repaired_num = get_repaired_num(newdata_res)\n",
    "\n",
    "    print('Aug', repaired_num/len(dis_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6aedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, constraint = pre_census_income.X_train, \\\n",
    "    pre_census_income.X_val, pre_census_income.y_train, pre_census_income.y_val, pre_census_income.constraint\n",
    "    \n",
    "X_test, y_test = pre_census_income.X_test, pre_census_income.y_test\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "models_map = { 'a': \"models/models_flipped_retrain/adult_a_flipped_retrained_model.h5\",\n",
    "            'r': \"models/models_flipped_retrain/adult_r_flipped_retrained_model.h5,,\n",
    "            'g': \"models/models_flipped_retrain/adult_g_flipped_retrained_model.h5\",\n",
    "            'a&r': \"models/models_flipped_retrain/adult_a&r_flipped_retrained_model.h5\",\n",
    "            'a&g': \"models/models_flipped_retrain/adult_a&g_flipped_retrained_model.h5\",\n",
    "            'r&g': \"models/models_flipped_retrain/adult_r&g_flipped_retrained_model.h5\",\n",
    "    \n",
    "}\n",
    "\n",
    "for attr in pos_map.keys():\n",
    "    print(\"attr\", attr)\n",
    "    target_model_path = models_map[attr]\n",
    "    data_name = f\"discriminatory_data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "    dis_data = np.load(data_name)\n",
    "    num_attribs = len(X_train[0])\n",
    "    protected_attribs = pos_map[attr]\n",
    "    similar_X = similar_set(dis_data, num_attribs, protected_attribs, constraint)\n",
    "\n",
    "    augmented_model = keras.models.load_model(target_model_path)\n",
    "    aug_data = (augmented_model.predict(dis_data) > 0.5).astype(int).flatten()\n",
    "    dis_num = 0\n",
    "    newdata_res = []\n",
    "\n",
    "    l = len(similar_X)\n",
    "    for i in range(l):\n",
    "        newdata_re = augmented_model.predict(similar_X[i])\n",
    "        newdata_re = (newdata_re > 0.5).astype(int).flatten()\n",
    "        newdata_res.append(newdata_re)\n",
    "    repaired_num = get_repaired_num(newdata_res)\n",
    "\n",
    "    print('Aug', repaired_num/len(dis_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead2bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
