{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692b401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_census_income\n",
    "import tensorflow.keras.backend as KTF\n",
    "import argparse\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(constraint[i][0], constraint[i][1]+1))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "def get_repaired_num(newdata_res):\n",
    "    # identify whether the instance is discriminatory w.r.t. the model\n",
    "    # print(x.shape)\n",
    "    # print(X_train[0].shape)\n",
    "    # y_pred = (model(tf.constant([X_train[0]])) > 0.5)\n",
    "    l = len(newdata_res)\n",
    "    for i in range(l-1):\n",
    "        tmp_acc = (newdata_res[i] == newdata_res[i + 1]) * 1\n",
    "        if i == 0:\n",
    "            acc = tmp_acc\n",
    "        else:\n",
    "            acc += tmp_acc\n",
    "    return np.sum(np.where(acc == l-1, True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4522570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr a\n",
      "WARNING:tensorflow:From /home/xiaofei/anaconda3/envs/debias/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/xiaofei/anaconda3/envs/debias/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/xiaofei/anaconda3/envs/debias/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Aug 0.4348434156697388\n",
      "attr r\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Aug 0.8528403018169637\n",
      "attr g\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Aug 0.7104122329944037\n",
      "attr a&r\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Aug 0.3693649641465481\n",
      "attr a&g\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Aug 0.3473111053890937\n",
      "attr r&g\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Aug 0.38234888078098805\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, constraint = pre_census_income.X_train, \\\n",
    "    pre_census_income.X_val, pre_census_income.y_train, pre_census_income.y_val, pre_census_income.constraint\n",
    "    \n",
    "X_test, y_test = pre_census_income.X_test, pre_census_income.y_test\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "models_map = { 'a': \"models/retrained_adv/a_adult_model_0.h5\",\n",
    "            'r': \"models/retrained_adv/r_adult_model_0.h5\",\n",
    "            'g': \"models/retrained_adv/g_adult_model_0.h5\",\n",
    "            'a&r': \"models/retrained_adv/a&r_adult_model_0.h5\",\n",
    "            'a&g': \"models/retrained_adv/a&g_adult_model_0.h5\",\n",
    "            'r&g': \"models/retrained_adv/r&g_adult_model_0.h5\",\n",
    "    \n",
    "}\n",
    "\n",
    "for attr in pos_map.keys():\n",
    "    print(\"attr\", attr)\n",
    "    target_model_path = models_map[attr]\n",
    "    data_name = f\"discriminatory_data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "    dis_data = np.load(data_name)\n",
    "    num_attribs = len(X_train[0])\n",
    "    protected_attribs = pos_map[attr]\n",
    "    similar_X = similar_set(dis_data, num_attribs, protected_attribs, constraint)\n",
    "\n",
    "    augmented_model = keras.models.load_model(target_model_path)\n",
    "    aug_data = (augmented_model.predict(dis_data) > 0.5).astype(int).flatten()\n",
    "    dis_num = 0\n",
    "    newdata_res = []\n",
    "\n",
    "    l = len(similar_X)\n",
    "    for i in range(l):\n",
    "        newdata_re = augmented_model.predict(similar_X[i])\n",
    "        newdata_re = (newdata_re > 0.5).astype(int).flatten()\n",
    "        newdata_res.append(newdata_re)\n",
    "    repaired_num = get_repaired_num(newdata_res)\n",
    "\n",
    "    print('Aug', repaired_num/len(dis_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab7cf3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr a\n",
      "Aug 0.9681136602503172\n",
      "attr r\n",
      "Aug 0.9548072168073125\n",
      "attr g\n",
      "Aug 0.947741782927406\n",
      "attr a&r\n",
      "Aug 0.9584397598228739\n",
      "attr a&g\n",
      "Aug 0.9615396692813495\n",
      "attr r&g\n",
      "Aug 0.9418334812477402\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, constraint = pre_census_income.X_train, \\\n",
    "    pre_census_income.X_val, pre_census_income.y_train, pre_census_income.y_val, pre_census_income.constraint\n",
    "    \n",
    "X_test, y_test = pre_census_income.X_test, pre_census_income.y_test\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "models_map = { 'a': \"models/models_my_attribute_wise_retrain/adult_a_EIDIG_INF_retrained_model.h5\",\n",
    "            'r': \"models/models_my_attribute_wise_retrain/adult_r_EIDIG_INF_retrained_model.h5\",\n",
    "            'g': \"models/models_my_attribute_wise_retrain/adult_g_EIDIG_INF_retrained_model.h5\",\n",
    "            'a&r': \"models/models_my_attribute_wise_retrain/adult_a&r_EIDIG_INF_retrained_model.h5\",\n",
    "            'a&g': \"models/models_my_attribute_wise_retrain/adult_a&g_EIDIG_INF_retrained_model.h5\",\n",
    "            'r&g': \"models/models_my_attribute_wise_retrain/adult_r&g_EIDIG_INF_retrained_model.h5\",\n",
    "    \n",
    "}\n",
    "\n",
    "for attr in pos_map.keys():\n",
    "    print(\"attr\", attr)\n",
    "    target_model_path = models_map[attr]\n",
    "    data_name = f\"discriminatory_data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "    dis_data = np.load(data_name)\n",
    "    num_attribs = len(X_train[0])\n",
    "    protected_attribs = pos_map[attr]\n",
    "    similar_X = similar_set(dis_data, num_attribs, protected_attribs, constraint)\n",
    "\n",
    "    augmented_model = keras.models.load_model(target_model_path, compile=False)\n",
    "    aug_data = (augmented_model.predict(dis_data) > 0.5).astype(int).flatten()\n",
    "    dis_num = 0\n",
    "    newdata_res = []\n",
    "\n",
    "    l = len(similar_X)\n",
    "    for i in range(l):\n",
    "        newdata_re = augmented_model.predict(similar_X[i])\n",
    "        newdata_re = (newdata_re > 0.5).astype(int).flatten()\n",
    "        newdata_res.append(newdata_re)\n",
    "    repaired_num = get_repaired_num(newdata_res)\n",
    "\n",
    "    print('Aug', repaired_num/len(dis_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c243169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr a\n",
      "Aug 0.45089754916944774\n",
      "attr r\n",
      "Aug 0.7668735144447812\n",
      "attr g\n",
      "Aug 0.8560205985129135\n",
      "attr a&r\n",
      "Aug 0.43269239530215\n",
      "attr a&g\n",
      "Aug 0.29342016843665414\n",
      "attr r&g\n",
      "Aug 0.5445879762022154\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, constraint = pre_census_income.X_train, \\\n",
    "    pre_census_income.X_val, pre_census_income.y_train, pre_census_income.y_val, pre_census_income.constraint\n",
    "    \n",
    "X_test, y_test = pre_census_income.X_test, pre_census_income.y_test\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "models_map = { 'a': \"models/models_flipped_retrain/adult_a_flipped_retrained_model.h5\",\n",
    "            'r': \"models/models_flipped_retrain/adult_r_flipped_retrained_model.h5\",\n",
    "            'g': \"models/models_flipped_retrain/adult_g_flipped_retrained_model.h5\",\n",
    "            'a&r': \"models/models_flipped_retrain/adult_a&r_flipped_retrained_model.h5\",\n",
    "            'a&g': \"models/models_flipped_retrain/adult_a&g_flipped_retrained_model.h5\",\n",
    "            'r&g': \"models/models_flipped_retrain/adult_r&g_flipped_retrained_model.h5\",\n",
    "    \n",
    "}\n",
    "\n",
    "for attr in pos_map.keys():\n",
    "    print(\"attr\", attr)\n",
    "    target_model_path = models_map[attr]\n",
    "    data_name = f\"discriminatory_data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "    dis_data = np.load(data_name)\n",
    "    num_attribs = len(X_train[0])\n",
    "    protected_attribs = pos_map[attr]\n",
    "    similar_X = similar_set(dis_data, num_attribs, protected_attribs, constraint)\n",
    "\n",
    "    augmented_model = keras.models.load_model(target_model_path, compile=False)\n",
    "    aug_data = (augmented_model.predict(dis_data) > 0.5).astype(int).flatten()\n",
    "    dis_num = 0\n",
    "    newdata_res = []\n",
    "\n",
    "    l = len(similar_X)\n",
    "    for i in range(l):\n",
    "        newdata_re = augmented_model.predict(similar_X[i])\n",
    "        newdata_re = (newdata_re > 0.5).astype(int).flatten()\n",
    "        newdata_res.append(newdata_re)\n",
    "    repaired_num = get_repaired_num(newdata_res)\n",
    "\n",
    "    print('Aug', repaired_num/len(dis_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d49e5cb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_bank_marketing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6b7fdbfb2f6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_bank_marketing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpre_bank_marketing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_bank_marketing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_bank_marketing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_bank_marketing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_bank_marketing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_bank_marketing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pre_bank_marketing' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, constraint = pre_bank_marketing.X_train, \\\n",
    "    pre_bank_marketing.X_val, pre_bank_marketing.y_train, pre_bank_marketing.y_val, pre_bank_marketing.constraint\n",
    "    \n",
    "X_test, y_test = pre_bank_marketing.X_test, pre_bank_marketing.y_test\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            }\n",
    "\n",
    "models_map = { 'a': \"models/retrained_adv/a_bank_model_0.h5\",\n",
    "    \n",
    "}\n",
    "\n",
    "for attr in pos_map.keys():\n",
    "    print(\"attr\", attr)\n",
    "    target_model_path = models_map[attr]\n",
    "    data_name = f\"discriminatory_data/bank/B-{attr}_ids_EIDIG_INF.npy\"\n",
    "    dis_data = np.load(data_name)\n",
    "    num_attribs = len(X_train[0])\n",
    "    protected_attribs = pos_map[attr]\n",
    "    similar_X = similar_set(dis_data, num_attribs, protected_attribs, constraint)\n",
    "\n",
    "    augmented_model = keras.models.load_model(target_model_path)\n",
    "    aug_data = (augmented_model.predict(dis_data) > 0.5).astype(int).flatten()\n",
    "    dis_num = 0\n",
    "    newdata_res = []\n",
    "\n",
    "    l = len(similar_X)\n",
    "    for i in range(l):\n",
    "        newdata_re = augmented_model.predict(similar_X[i])\n",
    "        newdata_re = (newdata_re > 0.5).astype(int).flatten()\n",
    "        newdata_res.append(newdata_re)\n",
    "    repaired_num = get_repaired_num(newdata_res)\n",
    "\n",
    "    print('Aug', repaired_num/len(dis_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c94ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, constraint = pre_bank_marketing.X_train, \\\n",
    "    pre_bank_marketing.X_val, pre_bank_marketing.y_train, pre_bank_marketing.y_val, pre_bank_marketing.constraint\n",
    "    \n",
    "X_test, y_test = pre_bank_marketing.X_test, pre_bank_marketing.y_test\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            }\n",
    "\n",
    "models_map = { 'a': \"models/models_my_attribute_wise_retrain/bank_a_EIDIG_INF_retrained_model.h5\",\n",
    "    \n",
    "}\n",
    "\n",
    "for attr in pos_map.keys():\n",
    "    print(\"attr\", attr)\n",
    "    target_model_path = models_map[attr]\n",
    "    data_name = f\"discriminatory_data/bank/B-{attr}_ids_EIDIG_INF.npy\"\n",
    "    dis_data = np.load(data_name)\n",
    "    num_attribs = len(X_train[0])\n",
    "    protected_attribs = pos_map[attr]\n",
    "    similar_X = similar_set(dis_data, num_attribs, protected_attribs, constraint)\n",
    "\n",
    "    augmented_model = keras.models.load_model(target_model_path)\n",
    "    aug_data = (augmented_model.predict(dis_data) > 0.5).astype(int).flatten()\n",
    "    dis_num = 0\n",
    "    newdata_res = []\n",
    "\n",
    "    l = len(similar_X)\n",
    "    for i in range(l):\n",
    "        newdata_re = augmented_model.predict(similar_X[i])\n",
    "        newdata_re = (newdata_re > 0.5).astype(int).flatten()\n",
    "        newdata_res.append(newdata_re)\n",
    "    repaired_num = get_repaired_num(newdata_res)\n",
    "\n",
    "    print('Aug', repaired_num/len(dis_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ffdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val, constraint = pre_bank_marketing.X_train, \\\n",
    "    pre_bank_marketing.X_val, pre_bank_marketing.y_train, pre_bank_marketing.y_val, pre_bank_marketing.constraint\n",
    "    \n",
    "X_test, y_test = pre_bank_marketing.X_test, pre_bank_marketing.y_test\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            }\n",
    "\n",
    "models_map = { 'a': \"models/models_flipped_retrain/bank_a_flipped_retrained_model.h5\",\n",
    "    \n",
    "}\n",
    "\n",
    "for attr in pos_map.keys():\n",
    "    print(\"attr\", attr)\n",
    "    target_model_path = models_map[attr]\n",
    "    data_name = f\"discriminatory_data/bank/B-{attr}_ids_EIDIG_INF.npy\"\n",
    "    dis_data = np.load(data_name)\n",
    "    num_attribs = len(X_train[0])\n",
    "    protected_attribs = pos_map[attr]\n",
    "    similar_X = similar_set(dis_data, num_attribs, protected_attribs, constraint)\n",
    "\n",
    "    augmented_model = keras.models.load_model(target_model_path)\n",
    "    aug_data = (augmented_model.predict(dis_data) > 0.5).astype(int).flatten()\n",
    "    dis_num = 0\n",
    "    newdata_res = []\n",
    "\n",
    "    l = len(similar_X)\n",
    "    for i in range(l):\n",
    "        newdata_re = augmented_model.predict(similar_X[i])\n",
    "        newdata_re = (newdata_re > 0.5).astype(int).flatten()\n",
    "        newdata_res.append(newdata_re)\n",
    "    repaired_num = get_repaired_num(newdata_res)\n",
    "\n",
    "    print('Aug', repaired_num/len(dis_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14fde0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
