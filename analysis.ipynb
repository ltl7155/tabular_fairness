{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_census_income\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "def my_loss_fun(y_true, y_pred):\n",
    "    # do whatever you want\n",
    "    return y_pred\n",
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, dense_len, min=-1, max=1, **kwargs):\n",
    "        super(ScaleLayer, self).__init__(**kwargs)\n",
    "        tf.keras.constraints.MinMaxNorm()\n",
    "        self.scale = K.variable([[1. for x in range(dense_len)]], name='ffff',\n",
    "                                constraint=lambda t: tf.clip_by_value(t, min, max))\n",
    "        self.dense_len = dense_len\n",
    "    def call(self, inputs, **kwargs):\n",
    "        m = inputs * self.scale\n",
    "        return m\n",
    "    def get_config(self):\n",
    "        config = {'dense_len': self.dense_len}\n",
    "        base_config = super(ScaleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "def construct_model(neurons, top_layer, name, min, max, need_weights=True):\n",
    "    in_shape = X_train.shape[1:]\n",
    "    input = keras.Input(shape=in_shape)\n",
    "    layer1 = keras.layers.Dense(30, name=\"layer1\")\n",
    "    d1 = ScaleLayer(30, min, max)\n",
    "    layer2 = keras.layers.Dense(20, name=\"layer2\")\n",
    "    d2 = ScaleLayer(20, min, max)\n",
    "    layer3 = keras.layers.Dense(15, name=\"layer3\")\n",
    "    d3 = ScaleLayer(15, min, max)\n",
    "    layer4 = keras.layers.Dense(15, name=\"layer4\")\n",
    "    d4 = ScaleLayer(15, min, max)\n",
    "    layer5 = keras.layers.Dense(10,name=\"layer5\")\n",
    "    d5 = ScaleLayer(10, min, max)\n",
    "    layer6 = keras.layers.Dense(1, activation=\"sigmoid\", name=\"layer6\")\n",
    "\n",
    "    layer_lst = [layer1, layer2, layer3, layer4, layer5]\n",
    "    ds = [d1, d2, d3, d4, d5]\n",
    "    for layer in layer_lst[0: top_layer]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = input\n",
    "    for i, l in enumerate(layer_lst):\n",
    "        x = l(x)\n",
    "        if i < top_layer:\n",
    "            x = ds[i](x)\n",
    "    x = layer6(x)\n",
    "\n",
    "    if not need_weights:\n",
    "        return keras.Model(input, x)\n",
    "\n",
    "    w = 0.\n",
    "    for i, re in enumerate(neurons):\n",
    "        neg = re[0]\n",
    "        pos = re[1]\n",
    "        d = ds[i]\n",
    "        for m in neg:\n",
    "            w = tf.math.add(w, d.weights[0][0][m])\n",
    "        for n in pos:\n",
    "            w = tf.math.subtract(w, d.weights[0][0][n])\n",
    "    new_w = tf.identity(tf.reshape(w, [1, 1]), name=name)\n",
    "\n",
    "    model = keras.Model(input, [x, new_w])\n",
    "    return model\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(constraint[i][0], constraint[i][1]+1))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "attr = 'g'\n",
    "protected_attribs = pos_map[attr]\n",
    "\n",
    "data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "# dis_data = np.load(data_name)\n",
    "\n",
    "dis_data = pre_census_income.X_train\n",
    "num_attribs = len(dis_data[0])\n",
    "new_data = dis_data.copy()\n",
    "new_data[:, 7] = 1 - dis_data[:, 7]\n",
    "\n",
    "similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_census_income.constraint)\n",
    "# similar_X = [dis_data, new_data]\n",
    "\n",
    "layer_map = [('layer1', 'scale_layer_5'), ('layer2', 'scale_layer_6'), ('layer3', 'scale_layer_7'), ('layer4', 'scale_layer_8'), ('layer5', 'scale_layer_8'), ('layer6', 'scale_layer_8')]\n",
    "\n",
    "layer_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 12)]              0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "scale_layer_5 (ScaleLayer)   (None, 30)                30        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "scale_layer_6 (ScaleLayer)   (None, 20)                20        \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "scale_layer_7 (ScaleLayer)   (None, 15)                15        \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "scale_layer_8 (ScaleLayer)   (None, 15)                15        \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,816\n",
      "Trainable params: 1,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "368.91714\n",
      "188515.02\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import pre_census_income\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model_path = \"models/diff_adult_g_gated_4_diff.h5\"\n",
    "# adult_g_gated_4_0.3_0.2_p-0.1_p0.9.h5\n",
    "model = keras.models.load_model(model_path, custom_objects={'ScaleLayer': ScaleLayer})\n",
    "model.summary()\n",
    "\n",
    "layer_name = layer_map[layer_index][1]\n",
    "inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "                                 \n",
    "layer_name = layer_map[layer_index][0]\n",
    "inter_model_before = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "                                 \n",
    "inter_output_ori = inter_model.predict(similar_X[0])\n",
    "inter_output_adv = inter_model.predict(similar_X[1])\n",
    "\n",
    "inter_output_ori_before = inter_model_before.predict(similar_X[0])\n",
    "inter_output_adv_before = inter_model_before.predict(similar_X[1])\n",
    "                                 \n",
    "print((np.abs(inter_output_adv - inter_output_ori)).sum())\n",
    "print((np.abs(inter_output_adv_before - inter_output_ori_before)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight [array([[ 7.5974339e-04, -5.3571258e-04, -5.2292697e-04, -8.3338644e-05,\n",
      "         1.9389287e-03,  2.4732639e-04, -4.9206632e-05,  2.5967529e-04,\n",
      "        -1.2399700e-01,  6.0464849e-04,  9.1479821e-03,  2.2583730e-04,\n",
      "         2.8091979e-03,  1.4539480e-03,  6.5577053e-04, -1.7852495e-04,\n",
      "         9.0948762e-03, -7.5216143e-05,  8.5201718e-05, -6.2989420e-04,\n",
      "         1.3095517e-02, -2.0224368e-04, -1.3083528e-03, -2.0436089e-02,\n",
      "         9.8191772e-04, -2.0736131e-04, -2.0158633e-03, -1.9681137e-03,\n",
      "        -8.8466989e-04,  4.5708522e-02]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "weight= model.get_layer('scale_layer_5').get_weights()\n",
    "print(\"weight\", weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': ['models/finetuned_models_protected_attributes/adult/r_adult_model_1_0.986.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_2_0.946.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_3_0.881.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_4_0.871.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_5_0.859.h5'], 'g': ['models/finetuned_models_protected_attributes/adult/g_adult_model_1_0.997.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_2_0.968.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_3_0.848.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_4_0.826.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_5_0.768.h5'], 'a': ['models/finetuned_models_protected_attributes/adult/a_adult_model_1_0.994.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_2_0.965.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_3_0.771.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_4_0.705.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_5_0.629.h5']}\n",
      "current_penalty [7 9] current_awarded []\n",
      "current_penalty [ 0  2  3  8 24 25 27] current_awarded [ 7 19 28]\n",
      "current_penalty [ 8 10 16 18] current_awarded [5 6]\n",
      "current_penalty [4] current_awarded [ 7  9 10]\n",
      "current_penalty [0 2 5 6 8] current_awarded [ 4 10]\n",
      "current_penalty [6 8 9] current_awarded [2 3]\n",
      "current_penalty [] current_awarded []\n",
      "current_penalty [] current_awarded []\n",
      "4.62468991960798\n",
      "1.3163425922393799\n",
      "16.62976989746094\n",
      "penalty [ 0  2  3  8 24 25 27]\n",
      "awarded [ 7 19 28]\n",
      "normal [1, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 26, 29]\n",
      "368.91714\n"
     ]
    }
   ],
   "source": [
    "from explain import  get_relevance, get_critical_neurons\n",
    "\n",
    "def my_filter(layer_critical, total_num):\n",
    "    i_unique, i_counts = np.unique(layer_critical, return_counts=True)\n",
    "    i_rates = i_counts / total_num\n",
    "    i_sort = np.where(i_rates > 0.2)[0]  # np.argsort(i_counts*-1)\n",
    "    i_critical = i_unique[i_sort]\n",
    "    return i_critical\n",
    "\n",
    "def get_path_dict():\n",
    "    saved_model_path = \"models/finetuned_models_protected_attributes/adult/\"\n",
    "    path_ls = os.listdir(saved_model_path)\n",
    "    path_dict = {}\n",
    "    path_dict['r'] = [saved_model_path+p for p in path_ls if \"r_adult\" in p]\n",
    "    path_dict['g'] = [saved_model_path+p for p in path_ls if \"g_adult\" in p]\n",
    "    path_dict['a'] = [saved_model_path+p for p in path_ls if \"a_adult\" in p]\n",
    "    path_dict['r'].sort()\n",
    "    path_dict['g'].sort()\n",
    "    path_dict['a'].sort()\n",
    "    print(path_dict)\n",
    "    return path_dict\n",
    "\n",
    "\n",
    "def get_penalty_awarded(top_n, layer_num, total_num, income_critical, protected_critical_ls):\n",
    "    neurons = []\n",
    "\n",
    "    for i in range(layer_num):\n",
    "        income_layer_critical = income_critical[i].flatten()\n",
    "        i_critical = my_filter(income_layer_critical, total_num)\n",
    "        current_penalty = None\n",
    "        current_awarded = None\n",
    "        filtered_criticals = []\n",
    "        j = 0\n",
    "        a = 'g'\n",
    "        protected_layer_critical = protected_critical_ls[j][i].flatten()\n",
    "        p_critical = my_filter(protected_layer_critical, total_num)\n",
    "        filtered_criticals.append(p_critical)\n",
    "        penalty = np.setdiff1d(p_critical, i_critical)\n",
    "        awarded = np.setdiff1d(i_critical, p_critical)\n",
    "        if current_penalty is None:\n",
    "            current_penalty = penalty\n",
    "        else:\n",
    "            current_penalty = np.union1d(current_penalty, penalty)\n",
    "        if current_awarded is None:\n",
    "            current_awarded = awarded\n",
    "        else:\n",
    "#                 current_awarded = np.intersect1d(current_awarded, awarded)\n",
    "            current_awarded = np.union1d(current_awarded, awarded)\n",
    "        print(\"current_penalty\", current_penalty, \"current_awarded\", current_awarded)\n",
    "        neurons.append((current_penalty, current_awarded))\n",
    "    neurons = neurons[1: (top_n + 1)]\n",
    "    return neurons\n",
    "\n",
    "\n",
    "path_dict = get_path_dict()\n",
    "model_path = \"models/adult_model.h5\"\n",
    "\n",
    "income_train_scores = get_relevance(model_path, pre_census_income.X_train,\n",
    "                                        save_path=os.path.join('scores/adult', os.path.basename(model_path) + \".score\"))\n",
    "income_critical = get_critical_neurons(income_train_scores, 0.3)\n",
    "finals = []\n",
    "\n",
    "top_n = 4\n",
    "protected_critical_ls = []\n",
    "\n",
    "a = 'g'\n",
    "path = path_dict[a][top_n - 1]\n",
    "train_scores = get_relevance(path, pre_census_income.X_train,  save_path=os.path.join('scores/adult', os.path.basename(path) + \".score\"))\n",
    "protected_critical = get_critical_neurons(train_scores, 0.3)\n",
    "protected_critical_ls.append(protected_critical)\n",
    "\n",
    "layer_num = len(income_critical)\n",
    "total_num = len(pre_census_income.X_train)\n",
    "neurons = get_penalty_awarded(top_n, layer_num, total_num, income_critical, protected_critical_ls)\n",
    "\n",
    "penalty = neurons[layer_index][0]\n",
    "awarded = neurons[layer_index][1]\n",
    "normal_neurons = [i for i in range(len(inter_output_adv[0])) if i not in neurons[layer_index][0] and i not in neurons[layer_index][1]]\n",
    "print((np.abs(inter_output_adv[:, penalty] - inter_output_ori[:, penalty])).sum() / len(penalty))\n",
    "print((np.abs(inter_output_adv[:, awarded] - inter_output_ori[:, awarded])).sum() / len(awarded))\n",
    "print((np.abs(inter_output_adv[:, normal_neurons] - inter_output_ori[:, normal_neurons])).sum() / len(normal_neurons))\n",
    "print(\"penalty\", penalty)\n",
    "print(\"awarded\", awarded)\n",
    "print(\"normal\", normal_neurons)\n",
    "\n",
    "print((np.abs(inter_output_adv - inter_output_ori)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 12)]              0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "scale_layer_5 (ScaleLayer)   (None, 30)                30        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "scale_layer_6 (ScaleLayer)   (None, 20)                20        \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "scale_layer_7 (ScaleLayer)   (None, 15)                15        \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "scale_layer_8 (ScaleLayer)   (None, 15)                15        \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,816\n",
      "Trainable params: 1,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "368.91714\n",
      "188515.02\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/diff_adult_g_gated_4_diff.h5\"\n",
    "# adult_g_gated_4_0.3_0.2_p-0.1_p0.2.h5\n",
    "model = keras.models.load_model(model_path, custom_objects={'ScaleLayer': ScaleLayer})\n",
    "model.summary()\n",
    "\n",
    "layer_name = layer_map[layer_index][1]\n",
    "inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "                                 \n",
    "layer_name = layer_map[layer_index][0]\n",
    "inter_model_before = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "                                 \n",
    "inter_output_ori = inter_model.predict(similar_X[0])\n",
    "inter_output_adv = inter_model.predict(similar_X[1])\n",
    "\n",
    "inter_output_ori_before = inter_model_before.predict(similar_X[0])\n",
    "inter_output_adv_before = inter_model_before.predict(similar_X[1])\n",
    "                                 \n",
    "print((np.abs(inter_output_adv - inter_output_ori)).sum())\n",
    "print((np.abs(inter_output_adv_before - inter_output_ori_before)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight [array([[ 7.5974339e-04, -5.3571258e-04, -5.2292697e-04, -8.3338644e-05,\n",
      "         1.9389287e-03,  2.4732639e-04, -4.9206632e-05,  2.5967529e-04,\n",
      "        -1.2399700e-01,  6.0464849e-04,  9.1479821e-03,  2.2583730e-04,\n",
      "         2.8091979e-03,  1.4539480e-03,  6.5577053e-04, -1.7852495e-04,\n",
      "         9.0948762e-03, -7.5216143e-05,  8.5201718e-05, -6.2989420e-04,\n",
      "         1.3095517e-02, -2.0224368e-04, -1.3083528e-03, -2.0436089e-02,\n",
      "         9.8191772e-04, -2.0736131e-04, -2.0158633e-03, -1.9681137e-03,\n",
      "        -8.8466989e-04,  4.5708522e-02]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "weight= model.get_layer('scale_layer_5').get_weights()\n",
    "print(\"weight\", weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_filter(layer_critical, total_num):\n",
    "    i_unique, i_counts = np.unique(layer_critical, return_counts=True)\n",
    "    i_rates = i_counts / total_num\n",
    "    i_sort = np.where(i_rates > 0.2)[0]  # np.argsort(i_counts*-1)\n",
    "    i_critical = i_unique[i_sort]\n",
    "    return i_critical\n",
    "\n",
    "def get_path_dict():\n",
    "    saved_model_path = \"models/finetuned_models_protected_attributes/adult/\"\n",
    "    path_ls = os.listdir(saved_model_path)\n",
    "    path_dict = {}\n",
    "    path_dict['r'] = [saved_model_path+p for p in path_ls if \"r_adult\" in p]\n",
    "    path_dict['g'] = [saved_model_path+p for p in path_ls if \"g_adult\" in p]\n",
    "    path_dict['a'] = [saved_model_path+p for p in path_ls if \"a_adult\" in p]\n",
    "    path_dict['r'].sort()\n",
    "    path_dict['g'].sort()\n",
    "    path_dict['a'].sort()\n",
    "    print(path_dict)\n",
    "    return path_dict\n",
    "\n",
    "def get_penalty_awarded(top_n, layer_num, total_num, income_critical, protected_critical_ls):\n",
    "    neurons = []\n",
    "\n",
    "    for i in range(layer_num):\n",
    "        income_layer_critical = income_critical[i].flatten()\n",
    "        i_critical = my_filter(income_layer_critical, total_num)\n",
    "        print(\"i_critical\", i_critical)\n",
    "        current_penalty = None\n",
    "        current_awarded = None\n",
    "        filtered_criticals = []\n",
    "        j = 0\n",
    "        a = 'g'\n",
    "        protected_layer_critical = protected_critical_ls[j][i].flatten()\n",
    "        p_critical = my_filter(protected_layer_critical, total_num)\n",
    "        print(\"p_critical\", p_critical)\n",
    "        filtered_criticals.append(p_critical)\n",
    "        penalty = np.setdiff1d(p_critical, i_critical)\n",
    "        awarded = np.setdiff1d(i_critical, p_critical)\n",
    "        if current_penalty is None:\n",
    "            current_penalty = penalty\n",
    "        else:\n",
    "            current_penalty = np.union1d(current_penalty, penalty)\n",
    "        if current_awarded is None:\n",
    "            current_awarded = awarded\n",
    "        else:\n",
    "#                 current_awarded = np.intersect1d(current_awarded, awarded)\n",
    "            current_awarded = np.union1d(current_awarded, awarded)\n",
    "        print(\"current_penalty\", current_penalty, \"current_awarded\", current_awarded)\n",
    "        neurons.append((current_penalty, current_awarded))\n",
    "    neurons = neurons[1: (top_n + 1)]\n",
    "    return neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': ['models/finetuned_models_protected_attributes/adult/r_adult_model_1_0.986.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_2_0.946.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_3_0.881.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_4_0.871.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_5_0.859.h5'], 'g': ['models/finetuned_models_protected_attributes/adult/g_adult_model_1_0.997.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_2_0.968.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_3_0.848.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_4_0.826.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_5_0.768.h5'], 'a': ['models/finetuned_models_protected_attributes/adult/a_adult_model_1_0.994.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_2_0.965.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_3_0.771.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_4_0.705.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_5_0.629.h5']}\n",
      "i_critical [ 2  8 10]\n",
      "p_critical [ 2  7  8  9 10]\n",
      "current_penalty [7 9] current_awarded []\n",
      "i_critical [ 7  9 10 14 15 16 19 20 22 28 29]\n",
      "p_critical [ 0  2  3  8  9 10 14 15 16 20 22 24 25 27 29]\n",
      "current_penalty [ 0  2  3  8 24 25 27] current_awarded [ 7 19 28]\n",
      "i_critical [ 0  2  3  5  6  9 12 13]\n",
      "p_critical [ 0  2  3  8  9 10 12 13 16 18]\n",
      "current_penalty [ 8 10 16 18] current_awarded [5 6]\n",
      "i_critical [ 1  5  7  8  9 10 12]\n",
      "p_critical [ 1  4  5  8 12]\n",
      "current_penalty [4] current_awarded [ 7  9 10]\n",
      "i_critical [ 1  4 10 14]\n",
      "p_critical [ 0  1  2  5  6  8 14]\n",
      "current_penalty [0 2 5 6 8] current_awarded [ 4 10]\n",
      "i_critical [1 2 3]\n",
      "p_critical [1 6 8 9]\n",
      "current_penalty [6 8 9] current_awarded [2 3]\n",
      "i_critical [0]\n",
      "p_critical [0]\n",
      "current_penalty [] current_awarded []\n",
      "i_critical [0]\n",
      "p_critical [0]\n",
      "current_penalty [] current_awarded []\n",
      "4.62468991960798\n",
      "1.3163425922393799\n",
      "16.62976989746094\n",
      "penalty [ 0  2  3  8 24 25 27]\n",
      "awarded [ 7 19 28]\n",
      "normal [1, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 26, 29]\n",
      "368.91714\n",
      "values [18152, 31258, 15933, 1934, 866, 0, 925, 29561, 11227, 20890, 2084, 0, 9117, 4931, 26667, 2939, 29646, 31112, 16416, 499, 701, 4023, 11977, 30030, 24653, 13093, 30061, 2620, 2807, 25711]\n",
      "values [19293, 31258, 17086, 1178, 495, 0, 2646, 28148, 11176, 24940, 2151, 0, 11449, 5449, 28666, 3807, 30057, 31184, 11340, 524, 837, 5430, 11060, 29997, 22811, 7076, 30456, 2445, 2770, 25468]\n"
     ]
    }
   ],
   "source": [
    "path_dict = get_path_dict()\n",
    "model_path = \"models/adult_model.h5\"\n",
    "\n",
    "income_train_scores = get_relevance(model_path, pre_census_income.X_train,\n",
    "                                        save_path=os.path.join('scores/adult', os.path.basename(model_path) + \".score\"))\n",
    "income_critical = get_critical_neurons(income_train_scores, 0.3)\n",
    "finals = []\n",
    "\n",
    "top_n = 4\n",
    "protected_critical_ls = []\n",
    "\n",
    "a = 'g'\n",
    "path = path_dict[a][top_n - 1]\n",
    "train_scores = get_relevance(path, pre_census_income.X_train,  save_path=os.path.join('scores/adult', os.path.basename(path) + \".score\"))\n",
    "protected_critical = get_critical_neurons(train_scores, 0.3)\n",
    "protected_critical_ls.append(protected_critical)\n",
    "\n",
    "layer_num = len(income_critical)\n",
    "total_num = len(pre_census_income.X_train)\n",
    "neurons = get_penalty_awarded(top_n, layer_num, total_num, income_critical, protected_critical_ls)\n",
    "\n",
    "penalty = neurons[layer_index][0]\n",
    "awarded = neurons[layer_index][1]\n",
    "normal_neurons = [i for i in range(len(inter_output_adv[0])) if i not in neurons[layer_index][0] and i not in neurons[layer_index][1]]\n",
    "print((np.abs(inter_output_adv[:, penalty] - inter_output_ori[:, penalty])).sum() / len(penalty))\n",
    "print((np.abs(inter_output_adv[:, awarded] - inter_output_ori[:, awarded])).sum() / len(awarded))\n",
    "print((np.abs(inter_output_adv[:, normal_neurons] - inter_output_ori[:, normal_neurons])).sum() / len(normal_neurons))\n",
    "print(\"penalty\", penalty)\n",
    "print(\"awarded\", awarded)\n",
    "print(\"normal\", normal_neurons)\n",
    "\n",
    "print((np.abs(inter_output_adv - inter_output_ori)).sum())\n",
    "\n",
    "# print(intermediate_output1 - intermediate_output0)\n",
    "\n",
    "s = [0 for i in range(len(inter_output_ori[0]))]\n",
    "for i in inter_output_ori:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] > 0:   \n",
    "            s[j] += 1\n",
    "print(\"values\", s)\n",
    "\n",
    "s = [0 for i in range(len(inter_output_adv[0]))]\n",
    "for i in inter_output_adv:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] > 0:   \n",
    "            s[j] += 1\n",
    "print(\"values\", s)\n",
    "# [0, 2, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.71061   ,  3.0536819 ,  2.024089  ,  0.58497125, 15.076021  ,\n",
       "        1.8527092 ,  0.569338  ,  1.9673985 , 17.34945   , 13.808918  ,\n",
       "       14.42024   ,  1.6813678 , 22.541544  ,  3.9344692 ,  7.0689754 ,\n",
       "        1.0338857 , 71.630424  ,  0.5526728 ,  1.275471  ,  0.97431767,\n",
       "       43.557945  ,  0.81608135,  3.742669  , 41.862415  ,  2.7926705 ,\n",
       "        2.3318763 , 23.685438  ,  4.577374  ,  1.0079285 , 60.42346   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.sum(np.abs(inter_output_adv - inter_output_ori), axis=0)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  6,  3, 21, 19, 28, 15, 18, 11,  5,  7,  2, 25,  0, 24,  1, 22,\n",
       "       13, 27, 14,  9, 10,  4,  8, 12, 26, 23, 20, 29, 16])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13762, 14828, 28289, 27386, 31148, 1354, 29, 26, 24738, 417, 28818, 26726, 1344, 949, 24587]\n"
     ]
    }
   ],
   "source": [
    "s = [0 for i in range(len(intermediate_output_ori_0[0]))]\n",
    "for i in intermediate_output_ori_0:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] > 0:   \n",
    "            s[j] += 1\n",
    "print(s)\n",
    "# [0, 2, 5, 6, 8, 12]\n",
    "#  [4, 9 ,10, 13, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,736\n",
      "Trainable params: 1,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "121393.95\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/adult_model.h5\"\n",
    "model = keras.models.load_model(model_path)\n",
    "model.summary()\n",
    "\n",
    "attr = 'g'\n",
    "protected_attribs = pos_map[attr]\n",
    "\n",
    "\n",
    "data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "dis_data = np.load(data_name)\n",
    "num_attribs = len(dis_data[0])\n",
    "\n",
    "similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_census_income.constraint)\n",
    "layer_name = 'layer1'\n",
    "intermediate_layer_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "\n",
    "intermediate_output0 = intermediate_layer_model.predict(similar_X[0])\n",
    "intermediate_output1 = intermediate_layer_model.predict(similar_X[1])\n",
    "print((np.abs(intermediate_output1 - intermediate_output0)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** layer 6\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 2.9423175 ],\n",
      "       [-1.499268  ],\n",
      "       [-0.73832774],\n",
      "       [-0.76415855],\n",
      "       [ 0.704021  ],\n",
      "       [-4.6148725 ],\n",
      "       [-0.95385844],\n",
      "       [-0.68753624],\n",
      "       [-1.078599  ],\n",
      "       [ 1.7334886 ]], dtype=float32), array([-0.18941183], dtype=float32)]\n",
      "ori: [ 2359.0288 11454.695   8508.35    9907.873   7318.1733  3739.8264\n",
      "  4917.8296  6825.021   6117.5737  2828.882 ]\n",
      "adv: [ 2357.3992 11503.09    8598.291   9938.546   7321.148   3746.182\n",
      "  4840.2847  6767.1963  6008.14    2808.0244]\n",
      "adv: [ 2349.4275 11460.468   8518.939   9911.51    7318.517   3742.564\n",
      "  4908.6523  6818.271   6104.6787  2833.443 ]\n",
      "adv: [ 2342.0198 11417.827   8439.612   9884.316   7315.7383  3739.092\n",
      "  4977.1416  6869.216   6201.2925  2859.8933]\n",
      "adv: [ 2335.0527 11375.365   8360.432   9857.31    7312.8735  3735.5918\n",
      "  5045.678   6919.6865  6297.935   2887.569 ]\n",
      "attr: a 0.011\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 1.0153329 ],\n",
      "       [-0.9641135 ],\n",
      "       [-0.31642342],\n",
      "       [-0.5854113 ],\n",
      "       [ 0.05338898],\n",
      "       [ 0.6885379 ],\n",
      "       [-0.5771605 ],\n",
      "       [-0.10637736],\n",
      "       [-0.07460939],\n",
      "       [ 0.39883998]], dtype=float32), array([-0.7370341], dtype=float32)]\n",
      "ori: [ 16838.348 143872.53  141993.88   48758.992  55379.543 193505.34\n",
      " 133942.69   74567.43   21999.02   64896.957]\n",
      "adv: [ 16335.137 146010.47  145217.95   49229.21   54755.363 200269.73\n",
      " 136277.84   76005.33   19991.096  67543.91 ]\n",
      "adv: [ 17384.225 140779.9   137655.83   48166.67   56135.863 185207.66\n",
      " 130808.66   72406.74   23899.314  59658.863]\n",
      "adv: [ 18588.83  135632.05  130223.74   47106.63   57516.88  170168.25\n",
      " 125409.92   68879.56   28600.545  52244.05 ]\n",
      "adv: [ 19916.605 130600.055 122937.195  46049.58   58899.25  155172.98\n",
      " 120090.836  65455.434  33670.98   45588.293]\n",
      "adv: [ 21348.852 125656.76  115847.93   44995.074  60282.2   140262.12\n",
      " 114848.48   62143.81   38892.496  39993.574]\n",
      "attr: r 0.131\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 1.628863  ],\n",
      "       [-1.3301833 ],\n",
      "       [-0.6820618 ],\n",
      "       [-0.87330616],\n",
      "       [ 0.22397429],\n",
      "       [ 0.17493378],\n",
      "       [-0.9055133 ],\n",
      "       [-0.6866539 ],\n",
      "       [-0.9403646 ],\n",
      "       [ 1.1410956 ]], dtype=float32), array([-0.57036096], dtype=float32)]\n",
      "ori: [10835.448  21020.066  14397.667  12782.292  23398.703  14409.551\n",
      " 11386.537   8021.8696  9309.046  11119.796 ]\n",
      "adv: [10778.498  20957.562  14249.4    12999.236  22779.861  14465.564\n",
      " 10852.852   8013.2974  9040.175  11033.468 ]\n",
      "adv: [10844.452 21051.275 14471.579 12674.1   23706.742 14381.662 11536.711\n",
      "  8002.802  9472.821 11121.495]\n",
      "attr: g 0.019\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 2.2137926 ],\n",
      "       [-1.3806503 ],\n",
      "       [-0.6174678 ],\n",
      "       [-0.7502243 ],\n",
      "       [ 0.5950738 ],\n",
      "       [ 4.0156794 ],\n",
      "       [-0.9614719 ],\n",
      "       [-0.43187112],\n",
      "       [-0.60759044],\n",
      "       [ 0.96419007]], dtype=float32), array([-0.17410778], dtype=float32)]\n",
      "ori: [ 3105.5188 16774.344  14452.347   9818.057   7357.1567  6157.7993\n",
      " 11087.232   9172.596   5937.0454  3104.3118]\n",
      "adv: [ 3079.5708 16818.771  14478.676   9895.667   7436.0767  6170.1387\n",
      " 10952.71    9083.977   5770.5273  3108.99  ]\n",
      "adv: [ 3143.6372 16702.346  14440.181   9585.802   7356.257   6171.3267\n",
      " 10875.066   9097.628   5738.7817  3090.61  ]\n",
      "adv: [ 3212.753  16586.     14401.916   9275.903   7276.359   6173.0513\n",
      " 10797.573   9111.211   5706.9546  3073.2046]\n",
      "adv: [ 3289.4106 16469.85   14363.695   8966.079   7196.7124  6175.05\n",
      " 10719.824   9124.842   5675.31    3056.7615]\n",
      "adv: [ 3375.06   16353.881  14325.358   8656.249   7117.149   6177.454\n",
      " 10642.354   9138.386   5643.789   3041.5293]\n",
      "adv: [ 3042.2305 16825.918  14470.676   9950.721   7398.5195  6170.116\n",
      " 11102.3545  9156.707   5935.0786  3127.9392]\n",
      "adv: [ 3102.8496 16709.605  14432.4     9640.983   7318.6733  6171.307\n",
      " 11024.646   9170.305   5902.4688  3108.839 ]\n",
      "adv: [ 3168.8545 16593.4    14394.171   9331.228   7239.045   6173.003\n",
      " 10947.104   9183.857   5870.1685  3090.4226]\n",
      "adv: [ 3240.1633 16477.242  14355.857   9021.451   7159.3755  6175.0264\n",
      " 10869.437   9197.442   5837.841   3073.0156]\n",
      "adv: [ 3320.7444 16361.249  14317.366   8711.505   7079.8584  6177.4185\n",
      " 10791.897   9211.015   5805.878   3056.5771]\n",
      "adv: [ 3006.8025 16833.156  14462.89   10006.171   7361.1562  6170.138\n",
      " 11251.933   9229.315   6104.9463  3147.707 ]\n",
      "adv: [ 3064.1946 16716.904  14424.66    9696.393   7281.4043  6171.2847\n",
      " 11174.282   9242.937   6071.1045  3127.7354]\n",
      "adv: [ 3126.7412 16600.824  14386.343   9386.463   7201.6343  6173.014\n",
      " 11096.68    9256.489   6037.6626  3108.6355]\n",
      "adv: [ 3194.7222 16484.695  14347.871   9076.62    7122.182   6175.019\n",
      " 11019.116   9270.035   6004.3394  3090.236 ]\n",
      "adv: [ 3268.4094 16368.426  14309.527   8766.807   7042.7085  6177.369\n",
      " 10941.432   9283.79    5971.163   3072.8523]\n",
      "adv: [ 2973.975  16840.436  14455.146  10061.358   7323.6704  6170.1665\n",
      " 11401.514   9301.952   6277.9463  3168.1587]\n",
      "adv: [ 3027.6938 16724.44   14416.822   9751.485   7243.874   6171.286\n",
      " 11323.966   9315.504   6243.8745  3147.499 ]\n",
      "adv: [ 3086.792  16608.076  14378.321   9441.816   7164.41    6172.949\n",
      " 11246.234   9329.094   6209.8325  3127.539 ]\n",
      "adv: [ 3151.638  16491.816  14340.031   9131.918   7084.919   6175.0396\n",
      " 11168.665   9342.915   6175.96    3108.4426]\n",
      "adv: [ 3221.2544 16375.68   14301.661   8822.063   7005.47    6177.3745\n",
      " 11091.06    9356.642   6142.0176  3090.1086]\n",
      "attr: a&r 0.03\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 2.2792    ],\n",
      "       [-1.4280014 ],\n",
      "       [-0.67357355],\n",
      "       [-0.806995  ],\n",
      "       [ 0.9950594 ],\n",
      "       [ 4.658464  ],\n",
      "       [-0.9574601 ],\n",
      "       [-0.6044746 ],\n",
      "       [-0.9065343 ],\n",
      "       [ 1.1332538 ]], dtype=float32), array([-0.02897025], dtype=float32)]\n",
      "ori: [ 2385.4485 15089.132  12386.036  11694.68    3883.9114  4251.534\n",
      "  8955.627   6129.3115  4927.381   4359.0625]\n",
      "adv: [ 2352.4397 15223.3955 12487.472  11739.226   3874.986   4233.2397\n",
      "  8901.029   6189.861   4938.89    4394.55  ]\n",
      "adv: [ 2359.8743 15113.176  12452.437  11759.294   3842.2341  4227.579\n",
      "  8993.086   6120.367   4927.961   4345.65  ]\n",
      "adv: [ 2354.1284 15169.943  12418.692  11688.096   3902.555   4234.742\n",
      "  8895.015   6177.093   4934.9004  4390.089 ]\n",
      "adv: [ 2362.8157 15059.887  12383.67   11708.203   3869.68    4228.2593\n",
      "  8987.004   6107.5635  4923.967   4341.2437]\n",
      "adv: [ 2356.2273 15116.94   12350.102  11636.914   3930.2788  4236.367\n",
      "  8888.927   6164.3735  4930.9326  4385.5117]\n",
      "adv: [ 2365.996  15005.905  12315.058  11656.817   3897.2446  4229.1543\n",
      "  8980.95    6094.85    4920.1025  4336.9087]\n",
      "adv: [ 2358.7063 15063.234  12281.514  11585.869   3958.0222  4238.18\n",
      "  8882.902   6151.514   4927.0923  4381.117 ]\n",
      "adv: [ 2369.3838 14952.321  12246.584  11605.51    3924.9004  4230.1978\n",
      "  8974.968   6082.077   4916.144   4332.5625]\n",
      "attr: a&g 0.01\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 1.1999272 ],\n",
      "       [-0.96391016],\n",
      "       [-0.33721024],\n",
      "       [-0.5057397 ],\n",
      "       [ 0.06308404],\n",
      "       [ 0.6637056 ],\n",
      "       [-0.52270865],\n",
      "       [-0.17834154],\n",
      "       [-0.28381583],\n",
      "       [ 0.74025375]], dtype=float32), array([-0.68805104], dtype=float32)]\n",
      "ori: [ 27056.879  97812.29  103802.5    34240.867  54569.105  96648.47\n",
      " 141662.12   25078.145  54398.184  17925.873]\n",
      "adv: [ 22357.268  95941.95   99860.11   28301.46   56275.492  99432.8\n",
      " 137236.14   23344.273  55261.02   18374.988]\n",
      "adv: [ 31323.037  98369.34  103326.76   35241.902  55917.785  97879.82\n",
      " 138631.67   25069.535  51697.805  18230.258]\n",
      "adv: [ 18432.164  96374.95  103584.67   25417.664  43182.36   95506.89\n",
      " 145243.1    23591.53   58720.35   15928.509]\n",
      "adv: [ 26608.627  98806.27  107087.15   29379.756  42896.94   93957.836\n",
      " 146656.23   25434.658  55127.508  15806.941]\n",
      "adv: [ 15416.824  96807.94  107347.96   25338.162  33361.54   91593.4\n",
      " 153334.66   23857.336  62205.58   13981.554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv: [ 22201.25   99245.52  110885.03   25889.88   33171.355  90053.12\n",
      " 154758.92   25823.424  58585.918  13891.614]\n",
      "adv: [ 13449.305  97239.766 111147.1    27713.45   28343.191  87700.11\n",
      " 161494.33   24143.588  65712.46   12652.975]\n",
      "adv: [ 18303.004  99685.89  114708.82   25128.916  28297.936  86168.9\n",
      " 162931.78   26229.027  62069.56   12601.897]\n",
      "adv: [ 12913.263  97674.016 114975.4    32195.588  30363.531  83829.59\n",
      " 169711.42   24452.701  69237.68   12078.011]\n",
      "adv: [ 15326.477 100130.14  118566.305  26944.873  30505.795  82306.52\n",
      " 171155.84   26651.402  65575.44   12064.745]\n",
      "attr: r&g 0.157\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_census_income\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "from scalelayer import  ScaleLayer\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "def my_loss_fun(y_true, y_pred):\n",
    "    # do whatever you want\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(constraint[i][0], constraint[i][1]+1))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "models_map = {\n",
    "    'a': \"models/gated_models/adult_a_gated_4_0.3_0.2_p-0.3_p0.15.h5\",\n",
    "    'r': \"models/gated_models/adult_r_gated_4_0.3_0.2_p-0.95_p0.8.h5\",\n",
    "    'g': \"models/gated_models/adult_g_gated_4_0.3_0.2_p-0.6_p0.1.h5\",\n",
    "    'a&r': \"models/gated_models/adult_a&r_gated_4_0.3_0.2_p-0.35_p0.25.h5\",\n",
    "    'a&g': \"models/gated_models/adult_a&g_gated_4_0.3_0.2_p-0.3_p0.25.h5\",\n",
    "    'r&g': \"models/gated_models/adult_r&g_gated_4_0.3_0.2_p-0.9_p0.8.h5\",\n",
    "}\n",
    "\n",
    "# similar_X = [dis_data, new_data]\n",
    "\n",
    "layer_map = [('layer1', 'scale_layer_5'), ('layer2', 'scale_layer_6'), ('layer3', 'scale_layer_7'), ('layer4', 'scale_layer_8'), ('layer5', 'layer5'), ('layer5', 'layer6')]\n",
    "\n",
    "from preprocessing import pre_census_income\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "for layer_index in range(5, 6):\n",
    "    print(\"*\"*10, \"layer\", layer_index+1)\n",
    "    for attr in pos_map.keys():\n",
    "        protected_attribs = pos_map[attr]\n",
    "        \n",
    "        model_path = models_map[attr]\n",
    "        # adult_g_gated_4_0.3_0.2_p-0.1_p0.9.h5\n",
    "        model = keras.models.load_model(model_path, custom_objects={'ScaleLayer': ScaleLayer})\n",
    "        print(model.get_layer('layer6').get_weights())\n",
    "#         model.summary()\n",
    "\n",
    "        # data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "        # dis_data = np.load(data_name)\n",
    "\n",
    "        dis_data = pre_census_income.X_train\n",
    "        num_attribs = len(dis_data[0])\n",
    "        new_data = dis_data.copy()\n",
    "\n",
    "        similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_census_income.constraint)\n",
    "\n",
    "        # layer_name = layer_map[layer_index][1]\n",
    "        # inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "\n",
    "        layer_name = layer_map[layer_index-1][1]\n",
    "        inter_model = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "\n",
    "        inter_output_ori = inter_model.predict(pre_census_income.X_train)\n",
    "        \n",
    "        max_v = inter_output_ori.max()\n",
    "        min_v = inter_output_ori.min()\n",
    "        print(\"ori:\", np.sum(np.abs(inter_output_ori), axis=0))\n",
    "        diff = 0\n",
    "        for i in range(len(similar_X)):\n",
    "            inter_output_adv = inter_model.predict(similar_X[i])\n",
    "            print(\"adv:\", np.sum(np.abs(inter_output_adv), axis=0))\n",
    "            diff += np.abs(inter_output_adv - inter_output_ori).sum() / (max_v - min_v)\n",
    "\n",
    "        num = len(similar_X) * similar_X[0].shape[0]\n",
    "        print(\"attr:\", attr, round(diff/num, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
