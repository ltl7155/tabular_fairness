{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_census_income\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "def my_loss_fun(y_true, y_pred):\n",
    "    # do whatever you want\n",
    "    return y_pred\n",
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, dense_len, min=-1, max=1, **kwargs):\n",
    "        super(ScaleLayer, self).__init__(**kwargs)\n",
    "        tf.keras.constraints.MinMaxNorm()\n",
    "        self.scale = K.variable([[1. for x in range(dense_len)]], name='ffff',\n",
    "                                constraint=lambda t: tf.clip_by_value(t, min, max))\n",
    "        self.dense_len = dense_len\n",
    "    def call(self, inputs, **kwargs):\n",
    "        m = inputs * self.scale\n",
    "        return m\n",
    "    def get_config(self):\n",
    "        config = {'dense_len': self.dense_len}\n",
    "        base_config = super(ScaleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "def construct_model(neurons, top_layer, name, min, max, need_weights=True):\n",
    "    in_shape = X_train.shape[1:]\n",
    "    input = keras.Input(shape=in_shape)\n",
    "    layer1 = keras.layers.Dense(30, name=\"layer1\")\n",
    "    d1 = ScaleLayer(30, min, max)\n",
    "    layer2 = keras.layers.Dense(20, name=\"layer2\")\n",
    "    d2 = ScaleLayer(20, min, max)\n",
    "    layer3 = keras.layers.Dense(15, name=\"layer3\")\n",
    "    d3 = ScaleLayer(15, min, max)\n",
    "    layer4 = keras.layers.Dense(15, name=\"layer4\")\n",
    "    d4 = ScaleLayer(15, min, max)\n",
    "    layer5 = keras.layers.Dense(10,name=\"layer5\")\n",
    "    d5 = ScaleLayer(10, min, max)\n",
    "    layer6 = keras.layers.Dense(1, activation=\"sigmoid\", name=\"layer6\")\n",
    "\n",
    "    layer_lst = [layer1, layer2, layer3, layer4, layer5]\n",
    "    ds = [d1, d2, d3, d4, d5]\n",
    "    for layer in layer_lst[0: top_layer]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = input\n",
    "    for i, l in enumerate(layer_lst):\n",
    "        x = l(x)\n",
    "        if i < top_layer:\n",
    "            x = ds[i](x)\n",
    "    x = layer6(x)\n",
    "\n",
    "    if not need_weights:\n",
    "        return keras.Model(input, x)\n",
    "\n",
    "    w = 0.\n",
    "    for i, re in enumerate(neurons):\n",
    "        neg = re[0]\n",
    "        pos = re[1]\n",
    "        d = ds[i]\n",
    "        for m in neg:\n",
    "            w = tf.math.add(w, d.weights[0][0][m])\n",
    "        for n in pos:\n",
    "            w = tf.math.subtract(w, d.weights[0][0][n])\n",
    "    new_w = tf.identity(tf.reshape(w, [1, 1]), name=name)\n",
    "\n",
    "    model = keras.Model(input, [x, new_w])\n",
    "    return model\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(constraint[i][0], constraint[i][1]+1))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "attr = 'g'\n",
    "protected_attribs = pos_map[attr]\n",
    "\n",
    "data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "# dis_data = np.load(data_name)\n",
    "\n",
    "dis_data = pre_census_income.X_train\n",
    "num_attribs = len(dis_data[0])\n",
    "new_data = dis_data.copy()\n",
    "new_data[:, 7] = 1 - dis_data[:, 7]\n",
    "\n",
    "similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_census_income.constraint)\n",
    "# similar_X = [dis_data, new_data]\n",
    "\n",
    "layer_map = [('layer1', 'scale_layer_5'), ('layer2', 'scale_layer_6'), ('layer3', 'scale_layer_7'), ('layer4', 'scale_layer_8'), ('layer5', 'scale_layer_8'), ('layer6', 'scale_layer_8')]\n",
    "\n",
    "layer_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 12)]              0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "scale_layer_5 (ScaleLayer)   (None, 30)                30        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "scale_layer_6 (ScaleLayer)   (None, 20)                20        \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "scale_layer_7 (ScaleLayer)   (None, 15)                15        \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "scale_layer_8 (ScaleLayer)   (None, 15)                15        \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,816\n",
      "Trainable params: 1,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "368.91714\n",
      "188515.02\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import pre_census_income\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model_path = \"models/diff_adult_g_gated_4_diff.h5\"\n",
    "# adult_g_gated_4_0.3_0.2_p-0.1_p0.9.h5\n",
    "model = keras.models.load_model(model_path, custom_objects={'ScaleLayer': ScaleLayer})\n",
    "model.summary()\n",
    "\n",
    "layer_name = layer_map[layer_index][1]\n",
    "inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "                                 \n",
    "layer_name = layer_map[layer_index][0]\n",
    "inter_model_before = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "                                 \n",
    "inter_output_ori = inter_model.predict(similar_X[0])\n",
    "inter_output_adv = inter_model.predict(similar_X[1])\n",
    "\n",
    "inter_output_ori_before = inter_model_before.predict(similar_X[0])\n",
    "inter_output_adv_before = inter_model_before.predict(similar_X[1])\n",
    "                                 \n",
    "print((np.abs(inter_output_adv - inter_output_ori)).sum())\n",
    "print((np.abs(inter_output_adv_before - inter_output_ori_before)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight [array([[ 7.5974339e-04, -5.3571258e-04, -5.2292697e-04, -8.3338644e-05,\n",
      "         1.9389287e-03,  2.4732639e-04, -4.9206632e-05,  2.5967529e-04,\n",
      "        -1.2399700e-01,  6.0464849e-04,  9.1479821e-03,  2.2583730e-04,\n",
      "         2.8091979e-03,  1.4539480e-03,  6.5577053e-04, -1.7852495e-04,\n",
      "         9.0948762e-03, -7.5216143e-05,  8.5201718e-05, -6.2989420e-04,\n",
      "         1.3095517e-02, -2.0224368e-04, -1.3083528e-03, -2.0436089e-02,\n",
      "         9.8191772e-04, -2.0736131e-04, -2.0158633e-03, -1.9681137e-03,\n",
      "        -8.8466989e-04,  4.5708522e-02]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "weight= model.get_layer('scale_layer_5').get_weights()\n",
    "print(\"weight\", weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': ['models/finetuned_models_protected_attributes/adult/r_adult_model_1_0.986.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_2_0.946.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_3_0.881.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_4_0.871.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_5_0.859.h5'], 'g': ['models/finetuned_models_protected_attributes/adult/g_adult_model_1_0.997.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_2_0.968.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_3_0.848.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_4_0.826.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_5_0.768.h5'], 'a': ['models/finetuned_models_protected_attributes/adult/a_adult_model_1_0.994.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_2_0.965.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_3_0.771.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_4_0.705.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_5_0.629.h5']}\n",
      "current_penalty [7 9] current_awarded []\n",
      "current_penalty [ 0  2  3  8 24 25 27] current_awarded [ 7 19 28]\n",
      "current_penalty [ 8 10 16 18] current_awarded [5 6]\n",
      "current_penalty [4] current_awarded [ 7  9 10]\n",
      "current_penalty [0 2 5 6 8] current_awarded [ 4 10]\n",
      "current_penalty [6 8 9] current_awarded [2 3]\n",
      "current_penalty [] current_awarded []\n",
      "current_penalty [] current_awarded []\n",
      "4.62468991960798\n",
      "1.3163425922393799\n",
      "16.62976989746094\n",
      "penalty [ 0  2  3  8 24 25 27]\n",
      "awarded [ 7 19 28]\n",
      "normal [1, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 26, 29]\n",
      "368.91714\n"
     ]
    }
   ],
   "source": [
    "from explain import  get_relevance, get_critical_neurons\n",
    "\n",
    "def my_filter(layer_critical, total_num):\n",
    "    i_unique, i_counts = np.unique(layer_critical, return_counts=True)\n",
    "    i_rates = i_counts / total_num\n",
    "    i_sort = np.where(i_rates > 0.2)[0]  # np.argsort(i_counts*-1)\n",
    "    i_critical = i_unique[i_sort]\n",
    "    return i_critical\n",
    "\n",
    "def get_path_dict():\n",
    "    saved_model_path = \"models/finetuned_models_protected_attributes/adult/\"\n",
    "    path_ls = os.listdir(saved_model_path)\n",
    "    path_dict = {}\n",
    "    path_dict['r'] = [saved_model_path+p for p in path_ls if \"r_adult\" in p]\n",
    "    path_dict['g'] = [saved_model_path+p for p in path_ls if \"g_adult\" in p]\n",
    "    path_dict['a'] = [saved_model_path+p for p in path_ls if \"a_adult\" in p]\n",
    "    path_dict['r'].sort()\n",
    "    path_dict['g'].sort()\n",
    "    path_dict['a'].sort()\n",
    "    print(path_dict)\n",
    "    return path_dict\n",
    "\n",
    "\n",
    "def get_penalty_awarded(top_n, layer_num, total_num, income_critical, protected_critical_ls):\n",
    "    neurons = []\n",
    "\n",
    "    for i in range(layer_num):\n",
    "        income_layer_critical = income_critical[i].flatten()\n",
    "        i_critical = my_filter(income_layer_critical, total_num)\n",
    "        current_penalty = None\n",
    "        current_awarded = None\n",
    "        filtered_criticals = []\n",
    "        j = 0\n",
    "        a = 'g'\n",
    "        protected_layer_critical = protected_critical_ls[j][i].flatten()\n",
    "        p_critical = my_filter(protected_layer_critical, total_num)\n",
    "        filtered_criticals.append(p_critical)\n",
    "        penalty = np.setdiff1d(p_critical, i_critical)\n",
    "        awarded = np.setdiff1d(i_critical, p_critical)\n",
    "        if current_penalty is None:\n",
    "            current_penalty = penalty\n",
    "        else:\n",
    "            current_penalty = np.union1d(current_penalty, penalty)\n",
    "        if current_awarded is None:\n",
    "            current_awarded = awarded\n",
    "        else:\n",
    "#                 current_awarded = np.intersect1d(current_awarded, awarded)\n",
    "            current_awarded = np.union1d(current_awarded, awarded)\n",
    "        print(\"current_penalty\", current_penalty, \"current_awarded\", current_awarded)\n",
    "        neurons.append((current_penalty, current_awarded))\n",
    "    neurons = neurons[1: (top_n + 1)]\n",
    "    return neurons\n",
    "\n",
    "\n",
    "path_dict = get_path_dict()\n",
    "model_path = \"models/adult_model.h5\"\n",
    "\n",
    "income_train_scores = get_relevance(model_path, pre_census_income.X_train,\n",
    "                                        save_path=os.path.join('scores/adult', os.path.basename(model_path) + \".score\"))\n",
    "income_critical = get_critical_neurons(income_train_scores, 0.3)\n",
    "finals = []\n",
    "\n",
    "top_n = 4\n",
    "protected_critical_ls = []\n",
    "\n",
    "a = 'g'\n",
    "path = path_dict[a][top_n - 1]\n",
    "train_scores = get_relevance(path, pre_census_income.X_train,  save_path=os.path.join('scores/adult', os.path.basename(path) + \".score\"))\n",
    "protected_critical = get_critical_neurons(train_scores, 0.3)\n",
    "protected_critical_ls.append(protected_critical)\n",
    "\n",
    "layer_num = len(income_critical)\n",
    "total_num = len(pre_census_income.X_train)\n",
    "neurons = get_penalty_awarded(top_n, layer_num, total_num, income_critical, protected_critical_ls)\n",
    "\n",
    "penalty = neurons[layer_index][0]\n",
    "awarded = neurons[layer_index][1]\n",
    "normal_neurons = [i for i in range(len(inter_output_adv[0])) if i not in neurons[layer_index][0] and i not in neurons[layer_index][1]]\n",
    "print((np.abs(inter_output_adv[:, penalty] - inter_output_ori[:, penalty])).sum() / len(penalty))\n",
    "print((np.abs(inter_output_adv[:, awarded] - inter_output_ori[:, awarded])).sum() / len(awarded))\n",
    "print((np.abs(inter_output_adv[:, normal_neurons] - inter_output_ori[:, normal_neurons])).sum() / len(normal_neurons))\n",
    "print(\"penalty\", penalty)\n",
    "print(\"awarded\", awarded)\n",
    "print(\"normal\", normal_neurons)\n",
    "\n",
    "print((np.abs(inter_output_adv - inter_output_ori)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 12)]              0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "scale_layer_5 (ScaleLayer)   (None, 30)                30        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "scale_layer_6 (ScaleLayer)   (None, 20)                20        \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "scale_layer_7 (ScaleLayer)   (None, 15)                15        \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "scale_layer_8 (ScaleLayer)   (None, 15)                15        \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,816\n",
      "Trainable params: 1,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "368.91714\n",
      "188515.02\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/diff_adult_g_gated_4_diff.h5\"\n",
    "# adult_g_gated_4_0.3_0.2_p-0.1_p0.2.h5\n",
    "model = keras.models.load_model(model_path, custom_objects={'ScaleLayer': ScaleLayer})\n",
    "model.summary()\n",
    "\n",
    "layer_name = layer_map[layer_index][1]\n",
    "inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "                                 \n",
    "layer_name = layer_map[layer_index][0]\n",
    "inter_model_before = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "                                 \n",
    "inter_output_ori = inter_model.predict(similar_X[0])\n",
    "inter_output_adv = inter_model.predict(similar_X[1])\n",
    "\n",
    "inter_output_ori_before = inter_model_before.predict(similar_X[0])\n",
    "inter_output_adv_before = inter_model_before.predict(similar_X[1])\n",
    "                                 \n",
    "print((np.abs(inter_output_adv - inter_output_ori)).sum())\n",
    "print((np.abs(inter_output_adv_before - inter_output_ori_before)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight [array([[ 7.5974339e-04, -5.3571258e-04, -5.2292697e-04, -8.3338644e-05,\n",
      "         1.9389287e-03,  2.4732639e-04, -4.9206632e-05,  2.5967529e-04,\n",
      "        -1.2399700e-01,  6.0464849e-04,  9.1479821e-03,  2.2583730e-04,\n",
      "         2.8091979e-03,  1.4539480e-03,  6.5577053e-04, -1.7852495e-04,\n",
      "         9.0948762e-03, -7.5216143e-05,  8.5201718e-05, -6.2989420e-04,\n",
      "         1.3095517e-02, -2.0224368e-04, -1.3083528e-03, -2.0436089e-02,\n",
      "         9.8191772e-04, -2.0736131e-04, -2.0158633e-03, -1.9681137e-03,\n",
      "        -8.8466989e-04,  4.5708522e-02]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "weight= model.get_layer('scale_layer_5').get_weights()\n",
    "print(\"weight\", weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_filter(layer_critical, total_num):\n",
    "    i_unique, i_counts = np.unique(layer_critical, return_counts=True)\n",
    "    i_rates = i_counts / total_num\n",
    "    i_sort = np.where(i_rates > 0.2)[0]  # np.argsort(i_counts*-1)\n",
    "    i_critical = i_unique[i_sort]\n",
    "    return i_critical\n",
    "\n",
    "def get_path_dict():\n",
    "    saved_model_path = \"models/finetuned_models_protected_attributes/adult/\"\n",
    "    path_ls = os.listdir(saved_model_path)\n",
    "    path_dict = {}\n",
    "    path_dict['r'] = [saved_model_path+p for p in path_ls if \"r_adult\" in p]\n",
    "    path_dict['g'] = [saved_model_path+p for p in path_ls if \"g_adult\" in p]\n",
    "    path_dict['a'] = [saved_model_path+p for p in path_ls if \"a_adult\" in p]\n",
    "    path_dict['r'].sort()\n",
    "    path_dict['g'].sort()\n",
    "    path_dict['a'].sort()\n",
    "    print(path_dict)\n",
    "    return path_dict\n",
    "\n",
    "def get_penalty_awarded(top_n, layer_num, total_num, income_critical, protected_critical_ls):\n",
    "    neurons = []\n",
    "\n",
    "    for i in range(layer_num):\n",
    "        income_layer_critical = income_critical[i].flatten()\n",
    "        i_critical = my_filter(income_layer_critical, total_num)\n",
    "        print(\"i_critical\", i_critical)\n",
    "        current_penalty = None\n",
    "        current_awarded = None\n",
    "        filtered_criticals = []\n",
    "        j = 0\n",
    "        a = 'g'\n",
    "        protected_layer_critical = protected_critical_ls[j][i].flatten()\n",
    "        p_critical = my_filter(protected_layer_critical, total_num)\n",
    "        print(\"p_critical\", p_critical)\n",
    "        filtered_criticals.append(p_critical)\n",
    "        penalty = np.setdiff1d(p_critical, i_critical)\n",
    "        awarded = np.setdiff1d(i_critical, p_critical)\n",
    "        if current_penalty is None:\n",
    "            current_penalty = penalty\n",
    "        else:\n",
    "            current_penalty = np.union1d(current_penalty, penalty)\n",
    "        if current_awarded is None:\n",
    "            current_awarded = awarded\n",
    "        else:\n",
    "#                 current_awarded = np.intersect1d(current_awarded, awarded)\n",
    "            current_awarded = np.union1d(current_awarded, awarded)\n",
    "        print(\"current_penalty\", current_penalty, \"current_awarded\", current_awarded)\n",
    "        neurons.append((current_penalty, current_awarded))\n",
    "    neurons = neurons[1: (top_n + 1)]\n",
    "    return neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': ['models/finetuned_models_protected_attributes/adult/r_adult_model_1_0.986.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_2_0.946.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_3_0.881.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_4_0.871.h5', 'models/finetuned_models_protected_attributes/adult/r_adult_model_5_0.859.h5'], 'g': ['models/finetuned_models_protected_attributes/adult/g_adult_model_1_0.997.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_2_0.968.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_3_0.848.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_4_0.826.h5', 'models/finetuned_models_protected_attributes/adult/g_adult_model_5_0.768.h5'], 'a': ['models/finetuned_models_protected_attributes/adult/a_adult_model_1_0.994.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_2_0.965.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_3_0.771.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_4_0.705.h5', 'models/finetuned_models_protected_attributes/adult/a_adult_model_5_0.629.h5']}\n",
      "i_critical [ 2  8 10]\n",
      "p_critical [ 2  7  8  9 10]\n",
      "current_penalty [7 9] current_awarded []\n",
      "i_critical [ 7  9 10 14 15 16 19 20 22 28 29]\n",
      "p_critical [ 0  2  3  8  9 10 14 15 16 20 22 24 25 27 29]\n",
      "current_penalty [ 0  2  3  8 24 25 27] current_awarded [ 7 19 28]\n",
      "i_critical [ 0  2  3  5  6  9 12 13]\n",
      "p_critical [ 0  2  3  8  9 10 12 13 16 18]\n",
      "current_penalty [ 8 10 16 18] current_awarded [5 6]\n",
      "i_critical [ 1  5  7  8  9 10 12]\n",
      "p_critical [ 1  4  5  8 12]\n",
      "current_penalty [4] current_awarded [ 7  9 10]\n",
      "i_critical [ 1  4 10 14]\n",
      "p_critical [ 0  1  2  5  6  8 14]\n",
      "current_penalty [0 2 5 6 8] current_awarded [ 4 10]\n",
      "i_critical [1 2 3]\n",
      "p_critical [1 6 8 9]\n",
      "current_penalty [6 8 9] current_awarded [2 3]\n",
      "i_critical [0]\n",
      "p_critical [0]\n",
      "current_penalty [] current_awarded []\n",
      "i_critical [0]\n",
      "p_critical [0]\n",
      "current_penalty [] current_awarded []\n",
      "4.62468991960798\n",
      "1.3163425922393799\n",
      "16.62976989746094\n",
      "penalty [ 0  2  3  8 24 25 27]\n",
      "awarded [ 7 19 28]\n",
      "normal [1, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 26, 29]\n",
      "368.91714\n",
      "values [18152, 31258, 15933, 1934, 866, 0, 925, 29561, 11227, 20890, 2084, 0, 9117, 4931, 26667, 2939, 29646, 31112, 16416, 499, 701, 4023, 11977, 30030, 24653, 13093, 30061, 2620, 2807, 25711]\n",
      "values [19293, 31258, 17086, 1178, 495, 0, 2646, 28148, 11176, 24940, 2151, 0, 11449, 5449, 28666, 3807, 30057, 31184, 11340, 524, 837, 5430, 11060, 29997, 22811, 7076, 30456, 2445, 2770, 25468]\n"
     ]
    }
   ],
   "source": [
    "path_dict = get_path_dict()\n",
    "model_path = \"models/adult_model.h5\"\n",
    "\n",
    "income_train_scores = get_relevance(model_path, pre_census_income.X_train,\n",
    "                                        save_path=os.path.join('scores/adult', os.path.basename(model_path) + \".score\"))\n",
    "income_critical = get_critical_neurons(income_train_scores, 0.3)\n",
    "finals = []\n",
    "\n",
    "top_n = 4\n",
    "protected_critical_ls = []\n",
    "\n",
    "a = 'g'\n",
    "path = path_dict[a][top_n - 1]\n",
    "train_scores = get_relevance(path, pre_census_income.X_train,  save_path=os.path.join('scores/adult', os.path.basename(path) + \".score\"))\n",
    "protected_critical = get_critical_neurons(train_scores, 0.3)\n",
    "protected_critical_ls.append(protected_critical)\n",
    "\n",
    "layer_num = len(income_critical)\n",
    "total_num = len(pre_census_income.X_train)\n",
    "neurons = get_penalty_awarded(top_n, layer_num, total_num, income_critical, protected_critical_ls)\n",
    "\n",
    "penalty = neurons[layer_index][0]\n",
    "awarded = neurons[layer_index][1]\n",
    "normal_neurons = [i for i in range(len(inter_output_adv[0])) if i not in neurons[layer_index][0] and i not in neurons[layer_index][1]]\n",
    "print((np.abs(inter_output_adv[:, penalty] - inter_output_ori[:, penalty])).sum() / len(penalty))\n",
    "print((np.abs(inter_output_adv[:, awarded] - inter_output_ori[:, awarded])).sum() / len(awarded))\n",
    "print((np.abs(inter_output_adv[:, normal_neurons] - inter_output_ori[:, normal_neurons])).sum() / len(normal_neurons))\n",
    "print(\"penalty\", penalty)\n",
    "print(\"awarded\", awarded)\n",
    "print(\"normal\", normal_neurons)\n",
    "\n",
    "print((np.abs(inter_output_adv - inter_output_ori)).sum())\n",
    "\n",
    "# print(intermediate_output1 - intermediate_output0)\n",
    "\n",
    "s = [0 for i in range(len(inter_output_ori[0]))]\n",
    "for i in inter_output_ori:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] > 0:   \n",
    "            s[j] += 1\n",
    "print(\"values\", s)\n",
    "\n",
    "s = [0 for i in range(len(inter_output_adv[0]))]\n",
    "for i in inter_output_adv:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] > 0:   \n",
    "            s[j] += 1\n",
    "print(\"values\", s)\n",
    "# [0, 2, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.71061   ,  3.0536819 ,  2.024089  ,  0.58497125, 15.076021  ,\n",
       "        1.8527092 ,  0.569338  ,  1.9673985 , 17.34945   , 13.808918  ,\n",
       "       14.42024   ,  1.6813678 , 22.541544  ,  3.9344692 ,  7.0689754 ,\n",
       "        1.0338857 , 71.630424  ,  0.5526728 ,  1.275471  ,  0.97431767,\n",
       "       43.557945  ,  0.81608135,  3.742669  , 41.862415  ,  2.7926705 ,\n",
       "        2.3318763 , 23.685438  ,  4.577374  ,  1.0079285 , 60.42346   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.sum(np.abs(inter_output_adv - inter_output_ori), axis=0)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  6,  3, 21, 19, 28, 15, 18, 11,  5,  7,  2, 25,  0, 24,  1, 22,\n",
       "       13, 27, 14,  9, 10,  4,  8, 12, 26, 23, 20, 29, 16])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13762, 14828, 28289, 27386, 31148, 1354, 29, 26, 24738, 417, 28818, 26726, 1344, 949, 24587]\n"
     ]
    }
   ],
   "source": [
    "s = [0 for i in range(len(intermediate_output_ori_0[0]))]\n",
    "for i in intermediate_output_ori_0:\n",
    "    for j in range(len(i)):\n",
    "        if i[j] > 0:   \n",
    "            s[j] += 1\n",
    "print(s)\n",
    "# [0, 2, 5, 6, 8, 12]\n",
    "#  [4, 9 ,10, 13, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,736\n",
      "Trainable params: 1,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "121393.95\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/adult_model.h5\"\n",
    "model = keras.models.load_model(model_path)\n",
    "model.summary()\n",
    "\n",
    "attr = 'g'\n",
    "protected_attribs = pos_map[attr]\n",
    "\n",
    "\n",
    "data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "dis_data = np.load(data_name)\n",
    "num_attribs = len(dis_data[0])\n",
    "\n",
    "similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_census_income.constraint)\n",
    "layer_name = 'layer1'\n",
    "intermediate_layer_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "\n",
    "intermediate_output0 = intermediate_layer_model.predict(similar_X[0])\n",
    "intermediate_output1 = intermediate_layer_model.predict(similar_X[1])\n",
    "print((np.abs(intermediate_output1 - intermediate_output0)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** layer 6\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 2.9423175 ],\n",
      "       [-1.499268  ],\n",
      "       [-0.73832774],\n",
      "       [-0.76415855],\n",
      "       [ 0.704021  ],\n",
      "       [-4.6148725 ],\n",
      "       [-0.95385844],\n",
      "       [-0.68753624],\n",
      "       [-1.078599  ],\n",
      "       [ 1.7334886 ]], dtype=float32), array([-0.18941183], dtype=float32)]\n",
      "ori: [ -903.33185 11454.695    8508.35     9907.873   -7318.1733  -1654.3573\n",
      " -4887.6245   6825.021    6117.362   -2102.9297 ]\n",
      "adv: [ -960.20404 11503.09     8598.291    9938.546   -7321.148   -1668.1406\n",
      " -4808.137    6767.1963   6007.7275  -2036.0569 ]\n",
      "adv: [ -910.04425 11460.468    8518.939    9911.51    -7318.517   -1655.9757\n",
      " -4878.2324   6818.271    6104.4106  -2095.0156 ]\n",
      "adv: [ -859.90497 11417.827    8439.612    9884.316   -7315.7383  -1643.8158\n",
      " -4948.333    6869.216    6201.129   -2154.0208 ]\n",
      "adv: [ -809.7314 11375.365   8360.432   9857.31   -7312.8735 -1631.6721\n",
      " -5018.4146  6919.6865  6297.853  -2212.9907]\n",
      "attr: a 0.011\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 1.0153329 ],\n",
      "       [-0.9641135 ],\n",
      "       [-0.31642342],\n",
      "       [-0.5854113 ],\n",
      "       [ 0.05338898],\n",
      "       [ 0.6885379 ],\n",
      "       [-0.5771605 ],\n",
      "       [-0.10637736],\n",
      "       [-0.07460939],\n",
      "       [ 0.39883998]], dtype=float32), array([-0.7370341], dtype=float32)]\n",
      "ori: [  -7157.177 -136118.08  -140074.31    48208.906  -55373.387 -193448.58\n",
      "  132309.45   -71962.195    9744.126   61780.914]\n",
      "adv: [  -6353.528  -138821.72   -143692.95     48707.11    -54747.418\n",
      " -200268.73    134910.72    -73804.805     6983.9614   65822.484 ]\n",
      "adv: [  -8129.772 -132846.7   -135694.44    47606.242  -56130.867 -185194.75\n",
      "  129162.54   -69731.95    13084.231   56889.7  ]\n",
      "adv: [  -9905.808 -126869.23  -127697.22    46505.15   -57513.902 -170122.7\n",
      "  123413.14   -65660.3     19184.422   47957.38 ]\n",
      "adv: [ -11682.134 -120894.54  -119699.484   45404.117  -58897.39  -155048.73\n",
      "  117664.98   -61587.715   25284.89    39025.316]\n",
      "adv: [ -13458.22  -114916.71  -111700.63    44303.062  -60281.06  -139976.98\n",
      "  111916.21   -57515.418   31385.248   30092.783]\n",
      "attr: r 0.131\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 1.628863  ],\n",
      "       [-1.3301833 ],\n",
      "       [-0.6820618 ],\n",
      "       [-0.87330616],\n",
      "       [ 0.22397429],\n",
      "       [ 0.17493378],\n",
      "       [-0.9055133 ],\n",
      "       [-0.6866539 ],\n",
      "       [-0.9403646 ],\n",
      "       [ 1.1410956 ]], dtype=float32), array([-0.57036096], dtype=float32)]\n",
      "ori: [  7864.5625  21020.066   14397.025   12781.858  -23398.703  -14409.551\n",
      "  -9455.373    2452.915    8860.51     6332.7656]\n",
      "adv: [  7778.1104  20957.562   14248.619   12999.028  -22779.861  -14465.564\n",
      "  -8793.904    2516.8672   8495.66     6169.3696]\n",
      "adv: [  7907.518   21051.275   14470.9375  12673.666  -23706.742  -14381.662\n",
      "  -9784.729    2421.056    9042.155    6414.147 ]\n",
      "attr: g 0.019\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 2.2137926 ],\n",
      "       [-1.3806503 ],\n",
      "       [-0.6174678 ],\n",
      "       [-0.7502243 ],\n",
      "       [ 0.5950738 ],\n",
      "       [ 4.0156794 ],\n",
      "       [-0.9614719 ],\n",
      "       [-0.43187112],\n",
      "       [-0.60759044],\n",
      "       [ 0.96419007]], dtype=float32), array([-0.17410778], dtype=float32)]\n",
      "ori: [ -1681.602    16774.344    14452.347     9818.057    -7348.4185\n",
      "   -266.74692 -11087.198     9172.307     5859.373    -1929.5151 ]\n",
      "adv: [ -1728.6359  16818.771   14478.676    9895.667   -7428.2993   -301.347\n",
      " -10952.621    9083.577    5664.488   -1890.2429]\n",
      "adv: [ -1910.3462   16702.346    14440.181     9585.802    -7347.3154\n",
      "   -224.01997 -10874.957     9097.244     5628.0127   -1831.6371 ]\n",
      "adv: [ -2092.1013   16586.       14401.916     9275.903    -7266.119\n",
      "   -146.69264 -10797.444     9110.84      5591.4917   -1773.0415 ]\n",
      "adv: [ -2273.8254   16469.85     14363.695     8966.079    -7185.0693\n",
      "    -69.36638 -10719.67      9124.486     5554.9126   -1714.4586 ]\n",
      "adv: [-2.4555532e+03  1.6353881e+04  1.4325358e+04  8.6562490e+03\n",
      " -7.1039268e+03  7.9609718e+00 -1.0642176e+04  9.1380420e+03\n",
      "  5.5184517e+03 -1.6558462e+03]\n",
      "adv: [ -1614.646    16825.918    14470.676     9950.721    -7390.203\n",
      "   -301.68893 -11102.305     9156.384     5850.9507   -1948.2709 ]\n",
      "adv: [ -1796.38     16709.605    14432.4       9640.983    -7309.1294\n",
      "   -224.36163 -11024.575     9169.994     5814.383    -1889.6827 ]\n",
      "adv: [ -1978.1123   16593.4      14394.171     9331.228    -7228.174\n",
      "   -147.03558 -10947.014     9183.561     5777.9263   -1831.0613 ]\n",
      "adv: [ -2159.8801   16477.242    14355.857     9021.451    -7147.018\n",
      "    -69.70924 -10869.325     9197.16      5741.267    -1772.4841 ]\n",
      "adv: [-2.3415959e+03  1.6361249e+04  1.4317366e+04  8.7115049e+03\n",
      " -7.0658389e+03  7.6172032e+00 -1.0791767e+04  9.2107461e+03\n",
      "  5.7048008e+03 -1.7138938e+03]\n",
      "adv: [ -1500.6615  16833.156   14462.89    10006.171   -7352.2773   -302.0322\n",
      " -11251.915    9229.059    6037.4033  -2006.2781]\n",
      "adv: [ -1682.3916   16716.904    14424.66      9696.393    -7271.2603\n",
      "   -224.70282 -11174.249     9242.689     6000.7236   -1947.6923 ]\n",
      "adv: [ -1864.109    16600.824    14386.343     9386.463    -7190.0845\n",
      "   -147.37854 -11096.629     9256.253     5964.262    -1889.0902 ]\n",
      "adv: [ -2045.8871    16484.695     14347.871      9076.62      -7109.0503\n",
      "    -70.052605 -11019.045      9269.809      5927.7495    -1830.4924  ]\n",
      "adv: [-2.2276204e+03  1.6368426e+04  1.4309527e+04  8.7668066e+03\n",
      " -7.0279028e+03  7.2736635e+00 -1.0941340e+04  9.2835713e+03\n",
      "  5.8910928e+03 -1.7719124e+03]\n",
      "adv: [ -1386.6692   16840.436    14455.146    10061.358    -7314.2256\n",
      "   -302.37558 -11401.506     9301.745     6223.723    -2064.297  ]\n",
      "adv: [ -1568.431   16724.44    14416.822    9751.485   -7233.086    -225.0497\n",
      " -11323.954    9315.308    6187.2104  -2005.7086]\n",
      "adv: [ -1750.165    16608.076    14378.321     9441.816    -7152.1484\n",
      "   -147.72395 -11246.214     9328.905     6150.567    -1947.1229 ]\n",
      "adv: [ -1931.9078   16491.816    14340.031     9131.918    -7071.0117\n",
      "    -70.39656 -11168.631     9342.735     6114.1606   -1888.5112 ]\n",
      "adv: [-2.1136680e+03  1.6375680e+04  1.4301661e+04  8.8220635e+03\n",
      " -6.9898540e+03  6.9292722e+00 -1.1091005e+04  9.3564717e+03\n",
      "  6.0775127e+03 -1.8299252e+03]\n",
      "attr: a&r 0.03\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 2.2792    ],\n",
      "       [-1.4280014 ],\n",
      "       [-0.67357355],\n",
      "       [-0.806995  ],\n",
      "       [ 0.9950594 ],\n",
      "       [ 4.658464  ],\n",
      "       [-0.9574601 ],\n",
      "       [-0.6044746 ],\n",
      "       [-0.9065343 ],\n",
      "       [ 1.1332538 ]], dtype=float32), array([-0.02897025], dtype=float32)]\n",
      "ori: [  177.99559 15089.132   12386.036   11694.68    -3501.4521   -554.7179\n",
      " -8955.233    6122.661    4879.4897  -4241.084  ]\n",
      "adv: [   56.388508 15223.3955   12487.472    11739.226    -3488.347\n",
      "  -638.9201   -8900.601     6184.252     4892.236    -4286.753   ]\n",
      "adv: [  178.37794 15113.176   12452.437   11759.294   -3442.0173   -454.41138\n",
      " -8992.759    6113.899    4880.428   -4227.484  ]\n",
      "adv: [   91.81375 15169.943   12418.692   11688.096   -3527.1711   -673.2889\n",
      " -8894.579    6171.33     4887.9404  -4281.3896 ]\n",
      "adv: [  213.80232 15059.887   12383.67    11708.203   -3480.8499   -488.78232\n",
      " -8986.671    6100.918    4876.1084  -4222.0664 ]\n",
      "adv: [  127.239944 15116.94     12350.102    11636.914    -3566.0312\n",
      "  -707.6559   -8888.486     6158.462     4883.645    -4275.914   ]\n",
      "adv: [  249.22754 15005.905   12315.058   11656.817   -3519.698    -523.1498\n",
      " -8980.611    6088.0186   4871.9316  -4216.7114 ]\n",
      "adv: [  162.66801 15063.234   12281.514   11585.869   -3604.849    -742.02203\n",
      " -8882.449    6145.4478   4879.4897  -4270.6133 ]\n",
      "adv: [  284.65494 14952.321   12246.584   11605.51    -3558.5137   -557.516\n",
      " -8974.62     6075.058    4867.63    -4211.3823 ]\n",
      "attr: a&g 0.01\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "[array([[ 1.1999272 ],\n",
      "       [-0.96391016],\n",
      "       [-0.33721024],\n",
      "       [-0.5057397 ],\n",
      "       [ 0.06308404],\n",
      "       [ 0.6637056 ],\n",
      "       [-0.52270865],\n",
      "       [-0.17834154],\n",
      "       [-0.28381583],\n",
      "       [ 0.74025375]], dtype=float32), array([-0.68805104], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori: [-24630.219 -87499.14  -94841.12  -20517.379 -46678.223 -95518.98\n",
      " 132039.97  -13240.224  52897.105  14268.59 ]\n",
      "adv: [-20090.334 -85232.44  -90230.72  -16879.857 -54386.137 -98446.19\n",
      " 126937.266  -9318.595  53781.707  16026.268]\n",
      "adv: [-30477.088 -88260.734 -94227.93  -28953.105 -53978.566 -96830.95\n",
      " 128507.37  -14581.212  49970.18   15828.5  ]\n",
      "adv: [-14799.329 -85774.83  -94523.41   -7106.212 -37951.02  -94359.09\n",
      " 135897.52  -10221.235  57449.957  12433.54 ]\n",
      "adv: [-25186.055 -88801.625 -98516.89  -19179.477 -37544.914 -92742.93\n",
      " 137469.14  -15483.978  53639.3    12235.564]\n",
      "adv: [ -9508.439  -86317.586  -98812.52     2667.3857 -21516.094  -90270.734\n",
      " 144858.     -11123.937   61119.06     8840.702 ]\n",
      "adv: [ -19895.094  -89342.98  -102810.28    -9405.733  -21110.127  -88656.6\n",
      "  146427.73   -16386.506   57307.938    8642.743]\n",
      "adv: [  -4217.4673  -86857.945  -103105.2      12441.083    -5081.4736\n",
      "  -86183.58    153818.      -12026.685    64787.86      5247.8936]\n",
      "adv: [ -14604.185    -89884.51    -107098.266       367.91275   -4675.291\n",
      "  -84569.98     155387.9      -17289.258     60976.26       5049.9644 ]\n",
      "adv: [   1073.4849  -87398.39   -107395.96     22214.613    11353.216\n",
      "  -82097.1     162777.69    -12929.335    68455.78      1655.0978]\n",
      "adv: [  -9313.196   -90427.95   -111391.7      10141.603    11759.397\n",
      "  -80481.52    164348.88    -18191.902    64644.87      1457.1537]\n",
      "attr: r&g 0.157\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_census_income\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "from scalelayer import  ScaleLayer\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "def my_loss_fun(y_true, y_pred):\n",
    "    # do whatever you want\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(constraint[i][0], constraint[i][1]+1))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "models_map = {\n",
    "    'a': \"models/gated_models/adult_a_gated_4_0.3_0.2_p-0.3_p0.15.h5\",\n",
    "    'r': \"models/gated_models/adult_r_gated_4_0.3_0.2_p-0.95_p0.8.h5\",\n",
    "    'g': \"models/gated_models/adult_g_gated_4_0.3_0.2_p-0.6_p0.1.h5\",\n",
    "    'a&r': \"models/gated_models/adult_a&r_gated_4_0.3_0.2_p-0.35_p0.25.h5\",\n",
    "    'a&g': \"models/gated_models/adult_a&g_gated_4_0.3_0.2_p-0.3_p0.25.h5\",\n",
    "    'r&g': \"models/gated_models/adult_r&g_gated_4_0.3_0.2_p-0.9_p0.8.h5\",\n",
    "}\n",
    "\n",
    "# similar_X = [dis_data, new_data]\n",
    "\n",
    "layer_map = [('layer1', 'scale_layer_5'), ('layer2', 'scale_layer_6'), ('layer3', 'scale_layer_7'), ('layer4', 'scale_layer_8'), ('layer5', 'layer5'), ('layer5', 'layer6')]\n",
    "\n",
    "from preprocessing import pre_census_income\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "for layer_index in range(5, 6):\n",
    "    print(\"*\"*10, \"layer\", layer_index+1)\n",
    "    for attr in pos_map.keys():\n",
    "        protected_attribs = pos_map[attr]\n",
    "        \n",
    "        model_path = models_map[attr]\n",
    "        # adult_g_gated_4_0.3_0.2_p-0.1_p0.9.h5\n",
    "        model = keras.models.load_model(model_path, custom_objects={'ScaleLayer': ScaleLayer})\n",
    "        print(model.get_layer('layer6').get_weights())\n",
    "#         model.summary()\n",
    "\n",
    "        # data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "        # dis_data = np.load(data_name)\n",
    "\n",
    "        dis_data = pre_census_income.X_train\n",
    "        num_attribs = len(dis_data[0])\n",
    "        new_data = dis_data.copy()\n",
    "\n",
    "        similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_census_income.constraint)\n",
    "\n",
    "        # layer_name = layer_map[layer_index][1]\n",
    "        # inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "\n",
    "        layer_name = layer_map[layer_index-1][1]\n",
    "        inter_model = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "\n",
    "        inter_output_ori = inter_model.predict(pre_census_income.X_train)\n",
    "        \n",
    "        max_v = inter_output_ori.max()\n",
    "        min_v = inter_output_ori.min()\n",
    "        print(\"ori:\", np.sum(inter_output_ori, axis=0))\n",
    "        diff = 0\n",
    "        for i in range(len(similar_X)):\n",
    "            inter_output_adv = inter_model.predict(similar_X[i])\n",
    "            print(\"adv:\", np.sum(inter_output_adv, axis=0))\n",
    "            diff += np.abs(inter_output_adv - inter_output_ori).sum() / (max_v - min_v)\n",
    "\n",
    "        num = len(similar_X) * similar_X[0].shape[0]\n",
    "        print(\"attr:\", attr, round(diff/num, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
