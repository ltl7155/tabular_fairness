{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ebf9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,736\n",
      "Trainable params: 1,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "layer 5\n",
      "attr: a 0.065\n",
      "attr: r 0.031\n",
      "attr: g 0.022\n",
      "attr: a&r 0.08\n",
      "attr: a&g 0.073\n",
      "attr: r&g 0.045\n",
      "layer 6\n",
      "attr: a 0.064\n",
      "attr: r 0.018\n",
      "attr: g 0.023\n",
      "attr: a&r 0.072\n",
      "attr: a&g 0.075\n",
      "attr: r&g 0.034\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_census_income\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "def my_loss_fun(y_true, y_pred):\n",
    "    # do whatever you want\n",
    "    return y_pred\n",
    "\n",
    "    \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=pre_census_income.X_train.shape[1:]),\n",
    "    keras.layers.Dense(20, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(constraint[i][0], constraint[i][1]+1))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "model_path = \"models/adult_model.h5\"\n",
    "# adult_g_gated_4_0.3_0.2_p-0.1_p0.9.h5\n",
    "model = keras.models.load_model(model_path)\n",
    "model.summary()\n",
    "\n",
    "# similar_X = [dis_data, new_data]\n",
    "\n",
    "layer_map = [('layer1', 'scale_layer_5'), ('layer2', 'scale_layer_6'), ('layer3', 'scale_layer_7'), ('layer4', 'scale_layer_8'), ('layer5', 'scale_layer_8'), ('layer6', 'scale_layer_8')]\n",
    "\n",
    "from preprocessing import pre_census_income\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "for layer_index in range(4, 6):\n",
    "    print(\"layer\", layer_index+1)\n",
    "    for attr in pos_map.keys():\n",
    "        protected_attribs = pos_map[attr]\n",
    "\n",
    "        # data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "        # dis_data = np.load(data_name)\n",
    "\n",
    "        dis_data = pre_census_income.X_train\n",
    "        num_attribs = len(dis_data[0])\n",
    "        new_data = dis_data.copy()\n",
    "\n",
    "        similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_census_income.constraint)\n",
    "\n",
    "        # layer_name = layer_map[layer_index][1]\n",
    "        # inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "\n",
    "        layer_name = layer_map[layer_index][0]\n",
    "        inter_model = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "\n",
    "        inter_output_ori = inter_model.predict(pre_census_income.X_train)\n",
    "\n",
    "        max_v = inter_output_ori.max()\n",
    "        min_v = inter_output_ori.min()\n",
    "        \n",
    "        diff = 0\n",
    "        for i in range(len(similar_X)):\n",
    "            inter_output_adv = inter_model.predict(similar_X[i])\n",
    "            diff += np.abs(inter_output_adv - inter_output_ori).sum() / (max_v - min_v)\n",
    "\n",
    "        num = len(similar_X) * similar_X[0].shape[0]\n",
    "        print(\"attr:\", attr, round(diff/num, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a8167d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xiaofei/anaconda3/envs/debias/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 30)                510       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,856\n",
      "Trainable params: 1,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "layer 0\n",
      "attr: a 0.493\n",
      "layer 1\n",
      "attr: a 0.394\n",
      "layer 2\n",
      "attr: a 0.196\n",
      "layer 3\n",
      "attr: a 0.115\n",
      "layer 4\n",
      "attr: a 0.078\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_bank_marketing\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "def my_loss_fun(y_true, y_pred):\n",
    "    # do whatever you want\n",
    "    return y_pred\n",
    "\n",
    "    \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=pre_bank_marketing.X_train.shape[1:]),\n",
    "    keras.layers.Dense(20, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(constraint[i][0], constraint[i][1]+1))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            }\n",
    "\n",
    "model_path = \"models/bank_model.h5\"\n",
    "# adult_g_gated_4_0.3_0.2_p-0.1_p0.9.h5\n",
    "model = keras.models.load_model(model_path)\n",
    "model.summary()\n",
    "\n",
    "# similar_X = [dis_data, new_data]\n",
    "\n",
    "layer_map = [('layer1', 'scale_layer_5'), ('layer2', 'scale_layer_6'), ('layer3', 'scale_layer_7'), ('layer4', 'scale_layer_8'), ('layer5', 'scale_layer_8'), ('dense_137', 'scale_layer_8')]\n",
    "\n",
    "from preprocessing import pre_bank_marketing\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "for layer_index in range(4,6):\n",
    "    print(\"layer\", layer_index)\n",
    "    for attr in pos_map.keys():\n",
    "        protected_attribs = pos_map[attr]\n",
    "\n",
    "        # data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "        # dis_data = np.load(data_name)\n",
    "\n",
    "        dis_data = pre_bank_marketing.X_train\n",
    "        num_attribs = len(dis_data[0])\n",
    "        new_data = dis_data.copy()\n",
    "\n",
    "        similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_bank_marketing.constraint)\n",
    "\n",
    "        # layer_name = layer_map[layer_index][1]\n",
    "        # inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "\n",
    "        layer_name = layer_map[layer_index][0]\n",
    "        inter_model = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "\n",
    "        inter_output_ori = inter_model.predict(pre_bank_marketing.X_train)\n",
    "        max_v = inter_output_ori.max()\n",
    "        min_v = inter_output_ori.min()\n",
    "\n",
    "        diff = 0\n",
    "        for i in range(len(similar_X)):\n",
    "            inter_output_adv = inter_model.predict(similar_X[i])\n",
    "            diff += np.abs(inter_output_adv - inter_output_ori).sum() / (max_v - min_v)\n",
    "\n",
    "        num = len(similar_X) * similar_X[0].shape[0]\n",
    "        print(\"attr:\", attr, round(diff/num, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d445c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,736\n",
      "Trainable params: 1,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "layer 5\n",
      "attr: a 0.045\n",
      "attr: r 0.045\n",
      "attr: g 0.013\n",
      "attr: a&r 0.068\n",
      "attr: a&g 0.05\n",
      "attr: r&g 0.05\n",
      "layer 6\n",
      "attr: a 0.03\n",
      "attr: r 0.036\n",
      "attr: g 0.009\n",
      "attr: a&r 0.049\n",
      "attr: a&g 0.033\n",
      "attr: r&g 0.039\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_census_income\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "def my_loss_fun(y_true, y_pred):\n",
    "    # do whatever you want\n",
    "    return y_pred\n",
    "\n",
    "    \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=pre_census_income.X_train.shape[1:]),\n",
    "    keras.layers.Dense(20, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(constraint[i][0], constraint[i][1]+1))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            'r': [6],\n",
    "            'g': [7],\n",
    "            'a&r': [0, 6],\n",
    "            'a&g': [0, 7],\n",
    "            'r&g': [6, 7]\n",
    "            }\n",
    "\n",
    "model_path = \"models/retrained_model_EIDIG/adult_EIDIG_INF_retrained_model.h5\"\n",
    "# adult_g_gated_4_0.3_0.2_p-0.1_p0.9.h5\n",
    "model = keras.models.load_model(model_path)\n",
    "model.summary()\n",
    "\n",
    "# similar_X = [dis_data, new_data]\n",
    "\n",
    "layer_map = [('layer1', 'scale_layer_5'), ('layer2', 'scale_layer_6'), ('layer3', 'scale_layer_7'), ('layer4', 'scale_layer_8'), ('layer5', 'scale_layer_8'), ('dense_5', 'scale_layer_8')]\n",
    "\n",
    "from preprocessing import pre_census_income\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "for layer_index in range(4, 6):\n",
    "    print(\"layer\", layer_index+1)\n",
    "    for attr in pos_map.keys():\n",
    "        protected_attribs = pos_map[attr]\n",
    "\n",
    "        # data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "        # dis_data = np.load(data_name)\n",
    "\n",
    "        dis_data = pre_census_income.X_train\n",
    "        num_attribs = len(dis_data[0])\n",
    "        new_data = dis_data.copy()\n",
    "\n",
    "        similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_census_income.constraint)\n",
    "\n",
    "        # layer_name = layer_map[layer_index][1]\n",
    "        # inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "\n",
    "        layer_name = layer_map[layer_index][0]\n",
    "        inter_model = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "\n",
    "        inter_output_ori = inter_model.predict(pre_census_income.X_train)\n",
    "        max_v = inter_output_ori.max()\n",
    "        min_v = inter_output_ori.min()\n",
    "\n",
    "        diff = 0\n",
    "        for i in range(len(similar_X)):\n",
    "            inter_output_adv = inter_model.predict(similar_X[i])\n",
    "            diff += np.abs(inter_output_adv - inter_output_ori).sum() / (max_v - min_v)\n",
    "\n",
    "        num = len(similar_X) * similar_X[0].shape[0]\n",
    "        print(\"attr:\", attr, round(diff/num, 3))\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061c5fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 30)                510       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 1,666\n",
      "Trainable params: 1,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "layer 0\n",
      "attr: a 0.356\n",
      "layer 1\n",
      "attr: a 0.184\n",
      "layer 2\n",
      "attr: a 0.061\n",
      "layer 3\n",
      "attr: a 0.023\n",
      "layer 4\n",
      "attr: a 0.012\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_bank_marketing\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "def my_loss_fun(y_true, y_pred):\n",
    "    # do whatever you want\n",
    "    return y_pred\n",
    "\n",
    "    \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=pre_bank_marketing.X_train.shape[1:]),\n",
    "    keras.layers.Dense(20, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(constraint[i][0], constraint[i][1]+1))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "pos_map = { 'a': [0],\n",
    "            }\n",
    "\n",
    "model_path = \"models/retrained_model_EIDIG/bank_EIDIG_INF_retrained_model.h5\"\n",
    "# adult_g_gated_4_0.3_0.2_p-0.1_p0.9.h5\n",
    "model = keras.models.load_model(model_path)\n",
    "model.summary()\n",
    "\n",
    "# similar_X = [dis_data, new_data]\n",
    "\n",
    "layer_map = [(\"layer1\", 'scale_layer_5'), ('layer2', 'scale_layer_6'), ('layer3', 'scale_layer_7'), ('layer4', 'scale_layer_8'), ('layer5', 'scale_layer_8'), ('dense_17', 'scale_layer_8')]\n",
    "\n",
    "from preprocessing import pre_bank_marketing\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "for layer_index in range(5):\n",
    "    print(\"layer\", layer_index)\n",
    "    for attr in pos_map.keys():\n",
    "        protected_attribs = pos_map[attr]\n",
    "\n",
    "        # data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "        # dis_data = np.load(data_name)\n",
    "\n",
    "        dis_data = pre_bank_marketing.X_train\n",
    "        num_attribs = len(dis_data[0])\n",
    "        new_data = dis_data.copy()\n",
    "\n",
    "        similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_bank_marketing.constraint)\n",
    "\n",
    "        # layer_name = layer_map[layer_index][1]\n",
    "        # inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "\n",
    "        layer_name = layer_map[layer_index][0]\n",
    "        inter_model = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "\n",
    "        inter_output_ori = inter_model.predict(pre_bank_marketing.X_train)\n",
    "        max_v = inter_output_ori.max()\n",
    "        min_v = inter_output_ori.min()\n",
    "\n",
    "        diff = 0\n",
    "        for i in range(len(similar_X)):\n",
    "            inter_output_adv = inter_model.predict(similar_X[i])\n",
    "            diff += np.abs(inter_output_adv - inter_output_ori).sum() / (max_v - min_v)\n",
    "\n",
    "        num = len(similar_X) * similar_X[0].shape[0]\n",
    "        print(\"attr:\", attr, round(diff/num, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b92fc285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 50)                600       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 2,816\n",
      "Trainable params: 2,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "layer 0\n",
      "attr: r 0.494\n",
      "attr: g 0.239\n",
      "attr: g&r 0.614\n",
      "layer 1\n",
      "attr: r 0.163\n",
      "attr: g 0.055\n",
      "attr: g&r 0.186\n",
      "layer 2\n",
      "attr: r 0.145\n",
      "attr: g 0.054\n",
      "attr: g&r 0.167\n",
      "layer 3\n",
      "attr: r 0.116\n",
      "attr: g 0.058\n",
      "attr: g&r 0.142\n",
      "layer 4\n",
      "attr: r 0.061\n",
      "attr: g 0.025\n",
      "attr: g&r 0.072\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_lsac\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "def my_loss_fun(y_true, y_pred):\n",
    "    # do whatever you want\n",
    "    return y_pred\n",
    "\n",
    "    \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(50, activation=\"relu\", input_shape=pre_lsac.X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(int(constraint[i][0]), int(constraint[i][1]+1)))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "pos_map = { \n",
    "            'r': [10],\n",
    "            'g': [9],\n",
    "            'g&r': [10, 9]\n",
    "            }\n",
    "\n",
    "model_path = \"models/lsac_model.h5\"\n",
    "# adult_g_gated_4_0.3_0.2_p-0.1_p0.9.h5\n",
    "model = keras.models.load_model(model_path)\n",
    "model.summary()\n",
    "\n",
    "# similar_X = [dis_data, new_data]\n",
    "\n",
    "layer_map = [('layer1', 'scale_layer_5'), ('layer2', 'scale_layer_6'), ('layer3', 'scale_layer_7'), ('layer4', 'scale_layer_8'), ('layer5', 'scale_layer_8')]\n",
    "\n",
    "from preprocessing import pre_lsac\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "for layer_index in range(5):\n",
    "    print(\"layer\", layer_index)\n",
    "    for attr in pos_map.keys():\n",
    "        protected_attribs = pos_map[attr]\n",
    "\n",
    "        # data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "        # dis_data = np.load(data_name)\n",
    "\n",
    "        dis_data = pre_lsac.X_train\n",
    "        num_attribs = len(dis_data[0])\n",
    "        new_data = dis_data.copy()\n",
    "\n",
    "        similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_lsac.constraint)\n",
    "\n",
    "        # layer_name = layer_map[layer_index][1]\n",
    "        # inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "\n",
    "        layer_name = layer_map[layer_index][0]\n",
    "        inter_model = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "\n",
    "        inter_output_ori = inter_model.predict(pre_lsac.X_train)\n",
    "        max_v = inter_output_ori.max()\n",
    "        min_v = inter_output_ori.min()\n",
    "\n",
    "        diff = 0\n",
    "        for i in range(len(similar_X)):\n",
    "            inter_output_adv = inter_model.predict(similar_X[i])\n",
    "            diff += np.abs(inter_output_adv - inter_output_ori).sum() / (max_v - min_v)\n",
    "\n",
    "        num = len(similar_X) * similar_X[0].shape[0]\n",
    "        print(\"attr:\", attr, round(diff/num, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19fdce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 50)                600       \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 2,816\n",
      "Trainable params: 2,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "layer 0\n",
      "attr: r 0.218\n",
      "attr: g 0.108\n",
      "attr: g&r 0.274\n",
      "layer 1\n",
      "attr: r 0.086\n",
      "attr: g 0.042\n",
      "attr: g&r 0.106\n",
      "layer 2\n",
      "attr: r 0.067\n",
      "attr: g 0.031\n",
      "attr: g&r 0.083\n",
      "layer 3\n",
      "attr: r 0.047\n",
      "attr: g 0.023\n",
      "attr: g&r 0.058\n",
      "layer 4\n",
      "attr: r 0.047\n",
      "attr: g 0.023\n",
      "attr: g&r 0.059\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from explain import  get_relevance, get_critical_neurons\n",
    "import tensorflow as tf\n",
    "# from tensorflow import set_random_seed\n",
    "from scalelayer import  ScaleLayer\n",
    "from numpy.random import seed\n",
    "import itertools\n",
    "import time\n",
    "import copy\n",
    "from preprocessing import pre_lsac\n",
    "import tensorflow.keras.backend as K\n",
    "import argparse\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_random_seed(2)\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True \n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)\n",
    "\n",
    "def my_loss_fun(y_true, y_pred):\n",
    "    # do whatever you want\n",
    "    return y_pred\n",
    "\n",
    "    \n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(50, activation=\"relu\", input_shape=pre_lsac.X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"relu\"),\n",
    "    keras.layers.Dense(5, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "def similar_set(X, num_attribs, protected_attribs, constraint):\n",
    "    # find all similar inputs corresponding to different combinations of protected attributes with non-protected attributes unchanged\n",
    "    similar_X = []\n",
    "    protected_domain = []\n",
    "    for i in protected_attribs:\n",
    "        protected_domain = protected_domain + [list(range(int(constraint[i][0]), int(constraint[i][1]+1)))]\n",
    "    all_combs = np.array(list(itertools.product(*protected_domain)))\n",
    "    for i, comb in enumerate(all_combs):\n",
    "        X_new = copy.deepcopy(X)\n",
    "        for a, c in zip(protected_attribs, comb):\n",
    "            X_new[:, a] = c\n",
    "        similar_X.append(X_new)\n",
    "    return similar_X\n",
    "\n",
    "pos_map = { \n",
    "            'r': [10],\n",
    "            'g': [9],\n",
    "            'g&r': [10, 9]\n",
    "            }\n",
    "\n",
    "model_path = \"models/retrained_model_EIDIG/lsac_EIDIG_INF_retrained_model.h5\"\n",
    "# adult_g_gated_4_0.3_0.2_p-0.1_p0.9.h5\n",
    "model = tf.keras.models.load_model(model_path, compile=False)\n",
    "model.summary()\n",
    "\n",
    "# similar_X = [dis_data, new_data]\n",
    "\n",
    "layer_map = [('layer1', 'scale_layer_5'), ('layer2', 'scale_layer_6'), ('layer3', 'scale_layer_7'), ('layer4', 'scale_layer_8'), ('layer5', 'scale_layer_8')]\n",
    "\n",
    "from preprocessing import pre_lsac\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "for layer_index in range(5):\n",
    "    print(\"layer\", layer_index)\n",
    "    for attr in pos_map.keys():\n",
    "        protected_attribs = pos_map[attr]\n",
    "\n",
    "        # data_name = f\"data/adult/C-{attr}_ids_EIDIG_INF.npy\"\n",
    "        # dis_data = np.load(data_name)\n",
    "\n",
    "        dis_data = pre_lsac.X_train\n",
    "        num_attribs = len(dis_data[0])\n",
    "        new_data = dis_data.copy()\n",
    "\n",
    "        similar_X = similar_set(dis_data, num_attribs, protected_attribs, pre_lsac.constraint)\n",
    "\n",
    "        # layer_name = layer_map[layer_index][1]\n",
    "        # inter_model = Model(model.input, model.get_layer(layer_name).output)\n",
    "\n",
    "        layer_name = layer_map[layer_index][0]\n",
    "        inter_model = Model(model.input, model.get_layer(layer_name).output)                                 \n",
    "\n",
    "        inter_output_ori = inter_model.predict(pre_lsac.X_train)\n",
    "        max_v = inter_output_ori.max()\n",
    "        min_v = inter_output_ori.min()\n",
    "\n",
    "        diff = 0\n",
    "        for i in range(len(similar_X)):\n",
    "            inter_output_adv = inter_model.predict(similar_X[i])\n",
    "            diff += np.abs(inter_output_adv - inter_output_ori).sum() / (max_v - min_v)\n",
    "\n",
    "        num = len(similar_X) * similar_X[0].shape[0]\n",
    "        print(\"attr:\", attr, round(diff/num, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebf6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080ae51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda47d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
